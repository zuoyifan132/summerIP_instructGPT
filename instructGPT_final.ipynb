{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8666af69-b34b-4dad-ab43-04db402b1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Callable, Tuple, Iterable\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "from torchtyping import TensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf08cbd-3808-4813-b68e-704b2ef13f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# clear CUDA memory cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392f90fa-7cd5-4806-8876-f4bc2c750434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PairDataset(Dataset):\n",
    "    \"\"\"Pairwise dataset for train reward model.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df, # A dataframe\n",
    "        tokenizer: Callable, # The tokenizer of the reward model\n",
    "        max_length: int = 1024 # Max context length of the reward model\n",
    "    ):\n",
    "\n",
    "        self.chosen = []\n",
    "        self.rejected = []\n",
    "\n",
    "        for _, data in tqdm(df.iterrows()):\n",
    "            chosen, rejected = data[\"chosen\"], data[\"rejected\"]\n",
    "            chosen_encoding = tokenizer(\n",
    "                chosen,\n",
    "                max_length=max_length, padding=\"max_length\", truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            rejected_encoding = tokenizer(\n",
    "                rejected,\n",
    "                max_length=max_length, padding=\"max_length\", truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            self.chosen.append({\n",
    "                \"input_ids\": chosen_encoding[\"input_ids\"],\n",
    "                \"attention_mask\": chosen_encoding[\"attention_mask\"]\n",
    "            })\n",
    "            self.rejected.append({\n",
    "                \"input_ids\": rejected_encoding[\"input_ids\"],\n",
    "                \"attention_mask\": rejected_encoding[\"attention_mask\"]\n",
    "            })\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.chosen)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.chosen[idx][\"input_ids\"],\\\n",
    "               self.chosen[idx][\"attention_mask\"],\\\n",
    "               self.rejected[idx][\"input_ids\"],\\\n",
    "               self.rejected[idx][\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6e78ca-d98f-43d6-a0db-df0ebbc82205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class IMDBDataset(Dataset):\n",
    "    \"\"\"Dataset for train RL-based language model.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df, # A dataframe\n",
    "        tokenizer: Callable, # The tokenizer of the language model\n",
    "        max_length: int = 1024 # Max context length of the language model\n",
    "    ):\n",
    "        self.text = []\n",
    "\n",
    "        for _, data in tqdm(df.iterrows()):\n",
    "            text  = data[\"text\"]\n",
    "            \n",
    "            # text_encoding = tokenizer(\n",
    "            #     text,\n",
    "            #     max_length=max_length, padding=\"max_length\", truncation=True,\n",
    "            #     return_tensors=\"pt\"\n",
    "            # )\n",
    "\n",
    "            self.text.append({\"text\": text})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.text[idx][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904c89c2-c7fb-4102-ad60-10c4244ac446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from typing import Callable, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torchtyping import TensorType\n",
    "\n",
    "from transformers import PreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae35d48-ea3f-44a1-bf8b-bea1e008e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Agent(nn.Module):\n",
    "    \"The RL-based language model.\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: PreTrainedModel # a pre-trained `transformers` model\n",
    "    ):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        For example, if n_embd is set to 768, then each input token will be\n",
    "        represented by a vector of length 768 in the pre-trained model's embedding space.\n",
    "        '''\n",
    "        n_embd = model.config.n_embd\n",
    "\n",
    "        '''\n",
    "        eos_token_id refers to the ID of the end-of-sequence token in the\n",
    "        pre-trained model's vocabulary. This token is used to indicate the end of a sequence,\n",
    "        such as the end of a sentence.\n",
    "        '''\n",
    "        self.eos_token_id = model.config.eos_token_id\n",
    "\n",
    "        '''\n",
    "        The policy network is responsible for taking the current state of the agent\n",
    "        (i.e., the previously generated words) and selecting the best action to take next.\n",
    "        '''\n",
    "        self.policy_network = model.to(\"cuda\")\n",
    "\n",
    "        '''\n",
    "        The value network is trained to predict the expected reward range from [-1, 1] that\n",
    "        the agent will receive in the future, given its current state.\n",
    "        '''\n",
    "        self.value_network = nn.Sequential(\n",
    "            nn.Linear(n_embd, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    '''\n",
    "    Get the predicted future reward for current state of all batch of inputs\n",
    "    '''\n",
    "    def get_value(\n",
    "        self, hidden_state: TensorType[\"batch_size\", \"seq_len\", \"n_embd\"]\n",
    "    ) -> TensorType[\"batch_size\", 1]:\n",
    "        \"\"\"Get value from the value network.\"\"\"\n",
    "        return self.value_network(hidden_state)[:, -1, :]\n",
    "\n",
    "    '''\n",
    "    The method takes as input an input_ids tensor, which represents the input\n",
    "    sequence of tokens to use as a starting point for the generation.\n",
    "    It then generates additional tokens one-by-one using the generate method\n",
    "    of the policy network (which is a pre-trained transformers model),\n",
    "    until it reaches the maximum sequence length or generates an end-of-sequence\n",
    "    token (if one is defined).\n",
    "    '''\n",
    "    def generate(\n",
    "        self,\n",
    "        input_ids: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        attention_mask: Optional[TensorType[\"batch_size\", \"seq_len\"]] = None,\n",
    "        **kwargs\n",
    "    ) -> TensorType[\"batch_size\", \"seq_len\"]:\n",
    "        output = self.policy_network.generate(\n",
    "            input_ids=input_ids.to(\"cuda\"), attention_mask=attention_mask.to(\"cuda\"), **kwargs\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    '''\n",
    "    Return randomly sample a word from the distribution and its corresponding logprob\n",
    "    and entropy of the whole distribution and the predicted reward of that sample word\n",
    "    '''\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        attention_mask: Optional[TensorType[\"batch_size, seq_len\"]] = None\n",
    "    ) -> Tuple[\n",
    "        TensorType[\"batch_size\", \"seq_len\", \"vocab_size\"],\n",
    "        TensorType[\"batch_size\", \"seq_len\", \"vocab_size\"],\n",
    "        TensorType[\"batch_size\", \"seq_len\"],\n",
    "        TensorType[\"batch_size\", 1]\n",
    "    ]: # action, logprobs, entropy, value\n",
    "\n",
    "        \"\"\"_summary_\"\"\"\n",
    "        if attention_mask is None:\n",
    "            '''\n",
    "            base_output:  the predicted probabilities for next token in the vocabulary,\n",
    "            and hidden states of each layer in the model:  the hidden state refers to\n",
    "            the output of each layer of the transformer.\n",
    "            '''\n",
    "            base_output = self.policy_network(\n",
    "                input_ids.to(\"cuda\"),\n",
    "                output_hidden_states=True,   # return the hidden states of all layers in model along with output\n",
    "            )\n",
    "        else:\n",
    "            base_output = self.policy_network(\n",
    "                input_ids.to(\"cuda\"), attention_mask=attention_mask.to(\"cuda\"),\n",
    "                output_hidden_states=True,\n",
    "            )\n",
    "\n",
    "        '''\n",
    "        The final layer state in the model that we need to fine-tuned\n",
    "        '''\n",
    "        last_hidden_state = base_output.hidden_states[-1]\n",
    "\n",
    "        '''\n",
    "        the logits tensor would contain the unnormalized scores or activations produced\n",
    "        by the model for each token in the vocabulary at each position in the sequence.\n",
    "        we only need to last word action value. shape: (batch_size, vocab_size)[]\n",
    "        '''\n",
    "        logits = base_output.logits[:, -1, :]\n",
    "\n",
    "        '''\n",
    "        the predicted probabilities for each token in the vocabulary for the last position word,\n",
    "        given the input sequence seen so far. probabilities sum to 1.\n",
    "        '''\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        '''\n",
    "        the categories correspond to the tokens in the model's vocabulary, and the\n",
    "        probabilities represent the predicted probabilities for each token given the input sequence seen so far.\n",
    "        '''\n",
    "        action_dist = Categorical(probs=probs)\n",
    "\n",
    "        '''\n",
    "        The sample() method of the Categorical distribution chooses an action stochastically based on the\n",
    "        probabilities of each action. Actions with higher probabilities have a higher chance of being sampled.\n",
    "        Action tensor contains the index of the token that was sampled from the probability distribution\n",
    "        defined by action_dist.\n",
    "        '''\n",
    "        action = action_dist.sample()\n",
    "\n",
    "        '''\n",
    "        The entropy of a probability distribution is a measure of the amount of information needed to describe\n",
    "        the distribution. A high entropy distribution is one where the probabilities of the different actions\n",
    "        are relatively equal, while a low entropy distribution is one where the probabilities are highly skewed\n",
    "        towards a particular action.\n",
    "        '''\n",
    "        entropy = action_dist.entropy()\n",
    "        logprobs = action_dist.log_prob(action)\n",
    "\n",
    "        # predicted reward value\n",
    "        '''\n",
    "        The last_hidden_state match the n_embd which is the pre-trained model's embedding space.\n",
    "        '''\n",
    "        value = self.get_value(last_hidden_state).squeeze(-1)\n",
    "\n",
    "        return action, logprobs, entropy, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6bbca00-b70c-421a-a48e-912aaae01289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RewardModel(nn.Module):\n",
    "    \"\"\"Reward model.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str, # `transformers`'s model name\n",
    "        dropout: float = 0.1,\n",
    "        device: str = 'cuda'\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "        config = model.config\n",
    "        n_embed = config.n_embd\n",
    "\n",
    "        self.model = model.to(device)\n",
    "\n",
    "        '''\n",
    "        custom head: a custom head that is added on top of the pre-trained language\n",
    "        model to adapt it to the specific task of summarization\n",
    "        '''\n",
    "        self.reward_head = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_embed, 1),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "\n",
    "    '''\n",
    "    ouput the reward value of the last generated\n",
    "    '''\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        attention_mask: TensorType[\"batch_size\", \"seq_len\"] = None,\n",
    "    ) -> TensorType[\"batch_size\", 1]: # A reward scalar for each item in a batch\n",
    "        \"\"\"Calculate reward for each item in a batch.\"\"\"\n",
    "\n",
    "        '''\n",
    "        last_hidden_state is the model output represents the hidden state output of\n",
    "        each position in the input sequence. The last_hidden_state match the n_embd\n",
    "        which is the pre-trained model's embedding space.\n",
    "        '''\n",
    "        last_hidden_state = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        ).last_hidden_state\n",
    "\n",
    "        '''\n",
    "        added layers of the pre-trained model to produce single value\n",
    "        '''\n",
    "        output = self.reward_head(last_hidden_state)\n",
    "\n",
    "        # for each item in the batch\n",
    "        # choose the hidden state of the last token as a reward!\n",
    "        '''\n",
    "        One reason for choosing the last token as the reward value is that it represents\n",
    "        the end of the input sequence, and therefore the end of the summary.\n",
    "        By selecting the reward value of the last token, the reward signal is directly\n",
    "        linked to the quality of the generated summary, which is the ultimate goal of the summarization task.\n",
    "        '''\n",
    "        reward_scalar = output[:, -1, 0]\n",
    "        return reward_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007df6cc-5704-4ee6-ad84-ae9bb30ac07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PairwiseLoss(nn.Module):\n",
    "    \"\"\"Pairwise loss function.\"\"\"\n",
    "    def forward(\n",
    "        self,\n",
    "        chosen_rewards: TensorType[\"batch_size\", 1], # The reward of the chosen prompt\n",
    "        rejected_rewards: TensorType[\"batch_size\", 1] # The reward of the rejected prompt\n",
    "    ) -> TensorType[1]: # A scalar loss\n",
    "        \"\"\"Compute the loss value.\"\"\"\n",
    "        assert len(chosen_rewards) == len(rejected_rewards)\n",
    "        batch_size = len(chosen_rewards)\n",
    "        probs = torch.sigmoid(chosen_rewards - rejected_rewards).log()\n",
    "        return -probs.mean() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107360c7-4d1e-4a0c-9f01-01a9fd832cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27db6f5-3670-479c-bd82-d9dd534bede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a reward model from a pre-trained language model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hy-tmp/gpt2_tokenizer_local\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "reward_model = RewardModel(model_name=\"hy-tmp/gpt2_local\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e807c1f2-85fe-4c43-a46a-dac2e7761ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a Pairwise dataset\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "sc_df = pd.read_csv(\"hy-tmp/openai_summarize_comparisons.csv\")\n",
    "sc_df = sc_df.iloc[:10000] # 10000/90000\n",
    "\n",
    "# # Convert the pandas DataFrame to a dataset\n",
    "# dataset = Dataset.from_dict(df.to_dict(orient='list')) \n",
    "\n",
    "# dataset = dataset.select(range(100))\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f1ad0f2-eba7-4b84-b22b-85535f72a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:14, 696.17it/s]\n"
     ]
    }
   ],
   "source": [
    "pair_dataset = PairDataset(sc_df, tokenizer)\n",
    "dataloader = DataLoader(pair_dataset, batch_size=4, num_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee53ba6a-de4e-4db2-90f2-3726a9bae39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Write a training loop\n",
    "N_EPOCHS = 1\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "pairwise_loss = PairwiseLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c60c13f-53d7-40eb-940e-56805aa40b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitRewardModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, model, loss_func, lr\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.lr = lr\n",
    "\n",
    "    def training_step(self, batch, batch_idx: int):\n",
    "        chosen_input_ids, chosen_attention_mask,\\\n",
    "        rejected_input_ids, rejected_attention_mask = batch\n",
    "\n",
    "        # call the forward function of the reward_model class\n",
    "        # then use the loss to train the parameters of pre-trained model and\n",
    "        # and custom head\n",
    "        chosen_rewards = self.model(chosen_input_ids, chosen_attention_mask)\n",
    "        rejected_rewards = self.model(rejected_input_ids, rejected_attention_mask)\n",
    "\n",
    "        loss = self.loss_func(chosen_rewards, rejected_rewards)\n",
    "\n",
    "        print(f\"loss={loss}\")\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab6867a4-da7e-4b18-b11f-28bcdd547095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # or \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8c67a6-8291-4af0-b04b-b8758fe27a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/usr/local/miniconda3/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:615: UserWarning: Checkpoint directory /checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | model     | RewardModel  | 124 M \n",
      "1 | loss_func | PairwiseLoss | 0     \n",
      "-------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "497.762   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2500 [00:00<?, ?it/s] loss=0.17953726649284363\n",
      "Epoch 0:   0%|          | 1/2500 [00:07<4:56:50,  7.13s/it]loss=0.16972096264362335\n",
      "Epoch 0:   0%|          | 2/2500 [00:07<2:38:48,  3.81s/it]loss=0.17343491315841675\n",
      "Epoch 0:   0%|          | 3/2500 [00:08<1:53:00,  2.72s/it]loss=0.19488877058029175\n",
      "Epoch 0:   0%|          | 4/2500 [00:08<1:29:51,  2.16s/it]loss=0.17288100719451904\n",
      "Epoch 0:   0%|          | 5/2500 [00:09<1:16:00,  1.83s/it]loss=0.17293569445610046\n",
      "Epoch 0:   0%|          | 6/2500 [00:09<1:06:48,  1.61s/it]loss=0.16975559294223785\n",
      "Epoch 0:   0%|          | 7/2500 [00:10<1:00:12,  1.45s/it]loss=0.17955680191516876\n",
      "Epoch 0:   0%|          | 8/2500 [00:10<55:20,  1.33s/it]  loss=0.14142440259456635\n",
      "Epoch 0:   0%|          | 9/2500 [00:11<51:28,  1.24s/it]loss=0.16438627243041992\n",
      "Epoch 0:   0%|          | 10/2500 [00:11<48:21,  1.17s/it]loss=0.17325296998023987\n",
      "Epoch 0:   0%|          | 11/2500 [00:12<45:49,  1.10s/it]loss=0.16932731866836548\n",
      "Epoch 0:   0%|          | 12/2500 [00:12<43:42,  1.05s/it]loss=0.1638326197862625\n",
      "Epoch 0:   1%|          | 13/2500 [00:13<41:55,  1.01s/it]loss=0.17055070400238037\n",
      "Epoch 0:   1%|          | 14/2500 [00:13<40:23,  1.03it/s]loss=0.1732870489358902\n",
      "Epoch 0:   1%|          | 15/2500 [00:14<39:03,  1.06it/s]loss=0.17329810559749603\n",
      "Epoch 0:   1%|          | 16/2500 [00:14<38:09,  1.08it/s]loss=0.1731904000043869\n",
      "Epoch 0:   1%|          | 17/2500 [00:15<37:06,  1.11it/s]loss=0.17322997748851776\n",
      "Epoch 0:   1%|          | 18/2500 [00:15<36:11,  1.14it/s]loss=0.17324480414390564\n",
      "Epoch 0:   1%|          | 19/2500 [00:16<35:20,  1.17it/s]loss=0.17338207364082336\n",
      "Epoch 0:   1%|          | 20/2500 [00:16<34:35,  1.19it/s]loss=0.1732797473669052\n",
      "Epoch 0:   1%|          | 21/2500 [00:17<33:54,  1.22it/s]loss=0.1723438948392868\n",
      "Epoch 0:   1%|          | 22/2500 [00:17<33:18,  1.24it/s]loss=0.17322508990764618\n",
      "Epoch 0:   1%|          | 23/2500 [00:18<32:44,  1.26it/s]loss=0.17430995404720306\n",
      "Epoch 0:   1%|          | 24/2500 [00:18<32:13,  1.28it/s]loss=0.17315340042114258\n",
      "Epoch 0:   1%|          | 25/2500 [00:19<31:44,  1.30it/s]loss=0.17315037548542023\n",
      "Epoch 0:   1%|          | 26/2500 [00:19<31:18,  1.32it/s]loss=0.1737034022808075\n",
      "Epoch 0:   1%|          | 27/2500 [00:20<30:53,  1.33it/s]loss=0.17349395155906677\n",
      "Epoch 0:   1%|          | 28/2500 [00:20<30:31,  1.35it/s]loss=0.1735033094882965\n",
      "Epoch 0:   1%|          | 29/2500 [00:21<30:09,  1.37it/s]loss=0.17328883707523346\n",
      "Epoch 0:   1%|          | 30/2500 [00:21<29:49,  1.38it/s]loss=0.17330864071846008\n",
      "Epoch 0:   1%|          | 31/2500 [00:22<29:31,  1.39it/s]loss=0.17346110939979553\n",
      "Epoch 0:   1%|▏         | 32/2500 [00:22<29:13,  1.41it/s]loss=0.17319625616073608\n",
      "Epoch 0:   1%|▏         | 33/2500 [00:23<28:57,  1.42it/s]loss=0.1760508120059967\n",
      "Epoch 0:   1%|▏         | 34/2500 [00:23<28:42,  1.43it/s]loss=0.1732950508594513\n",
      "Epoch 0:   1%|▏         | 35/2500 [00:24<28:27,  1.44it/s]loss=0.17326703667640686\n",
      "Epoch 0:   1%|▏         | 36/2500 [00:24<28:13,  1.45it/s]loss=0.1731521040201187\n",
      "Epoch 0:   1%|▏         | 37/2500 [00:25<28:01,  1.47it/s]loss=0.17335078120231628\n",
      "Epoch 0:   2%|▏         | 38/2500 [00:25<27:48,  1.48it/s]loss=0.17328716814517975\n",
      "Epoch 0:   2%|▏         | 39/2500 [00:26<27:36,  1.49it/s]loss=0.17328748106956482\n",
      "Epoch 0:   2%|▏         | 40/2500 [00:26<27:25,  1.49it/s]loss=0.17328612506389618\n",
      "Epoch 0:   2%|▏         | 41/2500 [00:27<27:15,  1.50it/s]loss=0.17328687012195587\n",
      "Epoch 0:   2%|▏         | 42/2500 [00:27<27:04,  1.51it/s]loss=0.1732868254184723\n",
      "Epoch 0:   2%|▏         | 43/2500 [00:28<26:54,  1.52it/s]loss=0.17328685522079468\n",
      "Epoch 0:   2%|▏         | 44/2500 [00:28<26:45,  1.53it/s]loss=0.17328676581382751\n",
      "Epoch 0:   2%|▏         | 45/2500 [00:29<26:36,  1.54it/s]loss=0.1732867807149887\n",
      "Epoch 0:   2%|▏         | 46/2500 [00:29<26:27,  1.55it/s]loss=0.17328672111034393\n",
      "Epoch 0:   2%|▏         | 47/2500 [00:30<26:19,  1.55it/s]loss=0.17328687012195587\n",
      "Epoch 0:   2%|▏         | 48/2500 [00:30<26:11,  1.56it/s]loss=0.17328676581382751\n",
      "Epoch 0:   2%|▏         | 49/2500 [00:31<26:04,  1.57it/s]loss=0.1732867956161499\n",
      "Epoch 0:   2%|▏         | 50/2500 [00:31<25:56,  1.57it/s]loss=0.17328648269176483\n",
      "Epoch 0:   2%|▏         | 51/2500 [00:32<25:49,  1.58it/s]loss=0.17328673601150513\n",
      "Epoch 0:   2%|▏         | 52/2500 [00:32<25:43,  1.59it/s]loss=0.1732867956161499\n",
      "Epoch 0:   2%|▏         | 53/2500 [00:33<25:36,  1.59it/s]loss=0.1732867956161499\n",
      "Epoch 0:   2%|▏         | 54/2500 [00:33<25:29,  1.60it/s]loss=0.1732868254184723\n",
      "Epoch 0:   2%|▏         | 55/2500 [00:34<25:23,  1.60it/s]loss=0.1732867956161499\n",
      "Epoch 0:   2%|▏         | 56/2500 [00:34<25:17,  1.61it/s]loss=0.1732867956161499\n",
      "Epoch 0:   2%|▏         | 57/2500 [00:35<25:11,  1.62it/s]loss=0.1732867956161499\n",
      "Epoch 0:   2%|▏         | 58/2500 [00:35<25:06,  1.62it/s]loss=0.1732867956161499\n",
      "Epoch 0:   2%|▏         | 59/2500 [00:36<25:00,  1.63it/s]loss=0.17328676581382751\n",
      "Epoch 0:   2%|▏         | 60/2500 [00:36<24:57,  1.63it/s]loss=0.1732867956161499\n",
      "Epoch 0:   2%|▏         | 61/2500 [00:37<24:53,  1.63it/s]loss=0.17328663170337677\n",
      "Epoch 0:   2%|▏         | 62/2500 [00:37<24:48,  1.64it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 63/2500 [00:38<24:43,  1.64it/s]loss=0.1732868254184723\n",
      "Epoch 0:   3%|▎         | 64/2500 [00:38<24:39,  1.65it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 65/2500 [00:39<24:35,  1.65it/s]loss=0.17328676581382751\n",
      "Epoch 0:   3%|▎         | 66/2500 [00:39<24:30,  1.66it/s]loss=0.1732868105173111\n",
      "Epoch 0:   3%|▎         | 67/2500 [00:40<24:26,  1.66it/s]loss=0.17328687012195587\n",
      "Epoch 0:   3%|▎         | 68/2500 [00:40<24:22,  1.66it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 69/2500 [00:41<24:17,  1.67it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 70/2500 [00:41<24:13,  1.67it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 71/2500 [00:42<24:10,  1.68it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 72/2500 [00:42<24:06,  1.68it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 73/2500 [00:43<24:02,  1.68it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 74/2500 [00:43<23:58,  1.69it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 75/2500 [00:44<23:55,  1.69it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 76/2500 [00:44<23:51,  1.69it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 77/2500 [00:45<23:48,  1.70it/s]loss=0.1732867807149887\n",
      "Epoch 0:   3%|▎         | 78/2500 [00:45<23:45,  1.70it/s]loss=0.17328642308712006\n",
      "Epoch 0:   3%|▎         | 79/2500 [00:46<23:42,  1.70it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 80/2500 [00:46<23:39,  1.71it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 81/2500 [00:47<23:36,  1.71it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 82/2500 [00:47<23:33,  1.71it/s]loss=0.1732868254184723\n",
      "Epoch 0:   3%|▎         | 83/2500 [00:48<23:30,  1.71it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 84/2500 [00:48<23:27,  1.72it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 85/2500 [00:49<23:24,  1.72it/s]loss=0.17328691482543945\n",
      "Epoch 0:   3%|▎         | 86/2500 [00:49<23:21,  1.72it/s]loss=0.1732867956161499\n",
      "Epoch 0:   3%|▎         | 87/2500 [00:50<23:19,  1.72it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▎         | 88/2500 [00:50<23:16,  1.73it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▎         | 89/2500 [00:51<23:13,  1.73it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▎         | 90/2500 [00:51<23:11,  1.73it/s]loss=0.17328670620918274\n",
      "Epoch 0:   4%|▎         | 91/2500 [00:52<23:08,  1.73it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▎         | 92/2500 [00:52<23:06,  1.74it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▎         | 93/2500 [00:53<23:04,  1.74it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 94/2500 [00:53<23:01,  1.74it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 95/2500 [00:54<22:59,  1.74it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 96/2500 [00:55<22:57,  1.75it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 97/2500 [00:55<22:55,  1.75it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 98/2500 [00:56<22:52,  1.75it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 99/2500 [00:56<22:50,  1.75it/s]loss=0.17328676581382751\n",
      "Epoch 0:   4%|▍         | 100/2500 [00:57<22:48,  1.75it/s]loss=0.17328675091266632\n",
      "Epoch 0:   4%|▍         | 101/2500 [00:57<22:46,  1.76it/s]loss=0.17328670620918274\n",
      "Epoch 0:   4%|▍         | 102/2500 [00:58<22:44,  1.76it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 103/2500 [00:58<22:42,  1.76it/s]loss=0.17328724265098572\n",
      "Epoch 0:   4%|▍         | 104/2500 [00:59<22:40,  1.76it/s]loss=0.17328673601150513\n",
      "Epoch 0:   4%|▍         | 105/2500 [00:59<22:38,  1.76it/s]loss=0.1732868105173111\n",
      "Epoch 0:   4%|▍         | 106/2500 [01:00<22:36,  1.76it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 107/2500 [01:00<22:34,  1.77it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 108/2500 [01:01<22:32,  1.77it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 109/2500 [01:01<22:30,  1.77it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 110/2500 [01:02<22:29,  1.77it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 111/2500 [01:02<22:27,  1.77it/s]loss=0.1732867956161499\n",
      "Epoch 0:   4%|▍         | 112/2500 [01:03<22:25,  1.77it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 113/2500 [01:03<22:23,  1.78it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 114/2500 [01:04<22:22,  1.78it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 115/2500 [01:04<22:20,  1.78it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 116/2500 [01:05<22:18,  1.78it/s]loss=0.1732868105173111\n",
      "Epoch 0:   5%|▍         | 117/2500 [01:05<22:16,  1.78it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 118/2500 [01:06<22:15,  1.78it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 119/2500 [01:06<22:13,  1.79it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 120/2500 [01:07<22:11,  1.79it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 121/2500 [01:07<22:10,  1.79it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 122/2500 [01:08<22:08,  1.79it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 123/2500 [01:08<22:06,  1.79it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▍         | 124/2500 [01:09<22:05,  1.79it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 125/2500 [01:09<22:03,  1.79it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 126/2500 [01:10<22:02,  1.80it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 127/2500 [01:10<22:00,  1.80it/s]loss=0.17328675091266632\n",
      "Epoch 0:   5%|▌         | 128/2500 [01:11<21:59,  1.80it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 129/2500 [01:11<21:57,  1.80it/s]loss=0.1732865273952484\n",
      "Epoch 0:   5%|▌         | 130/2500 [01:12<21:56,  1.80it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 131/2500 [01:12<21:54,  1.80it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 132/2500 [01:13<21:53,  1.80it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 133/2500 [01:13<21:52,  1.80it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 134/2500 [01:14<21:50,  1.81it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 135/2500 [01:14<21:49,  1.81it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 136/2500 [01:15<21:47,  1.81it/s]loss=0.1732867956161499\n",
      "Epoch 0:   5%|▌         | 137/2500 [01:15<21:46,  1.81it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 138/2500 [01:16<21:45,  1.81it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 139/2500 [01:16<21:43,  1.81it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 140/2500 [01:17<21:42,  1.81it/s]loss=0.1732867807149887\n",
      "Epoch 0:   6%|▌         | 141/2500 [01:17<21:40,  1.81it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 142/2500 [01:18<21:39,  1.81it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 143/2500 [01:18<21:38,  1.82it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 144/2500 [01:19<21:37,  1.82it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 145/2500 [01:19<21:35,  1.82it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 146/2500 [01:20<21:34,  1.82it/s]loss=0.17328675091266632\n",
      "Epoch 0:   6%|▌         | 147/2500 [01:20<21:33,  1.82it/s]loss=0.17328698933124542\n",
      "Epoch 0:   6%|▌         | 148/2500 [01:21<21:32,  1.82it/s]loss=0.17328692972660065\n",
      "Epoch 0:   6%|▌         | 149/2500 [01:21<21:31,  1.82it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 150/2500 [01:22<21:29,  1.82it/s]loss=0.17328675091266632\n",
      "Epoch 0:   6%|▌         | 151/2500 [01:22<21:28,  1.82it/s]loss=0.17328648269176483\n",
      "Epoch 0:   6%|▌         | 152/2500 [01:23<21:27,  1.82it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 153/2500 [01:23<21:26,  1.82it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 154/2500 [01:24<21:25,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 155/2500 [01:24<21:23,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▌         | 156/2500 [01:25<21:22,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▋         | 157/2500 [01:25<21:21,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▋         | 158/2500 [01:26<21:20,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▋         | 159/2500 [01:26<21:19,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▋         | 160/2500 [01:27<21:18,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▋         | 161/2500 [01:27<21:17,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   6%|▋         | 162/2500 [01:28<21:15,  1.83it/s]loss=0.17328660190105438\n",
      "Epoch 0:   7%|▋         | 163/2500 [01:28<21:14,  1.83it/s]loss=0.1732868105173111\n",
      "Epoch 0:   7%|▋         | 164/2500 [01:29<21:13,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 165/2500 [01:29<21:12,  1.83it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 166/2500 [01:30<21:11,  1.84it/s]loss=0.17328676581382751\n",
      "Epoch 0:   7%|▋         | 167/2500 [01:30<21:10,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 168/2500 [01:31<21:09,  1.84it/s]loss=0.1732867807149887\n",
      "Epoch 0:   7%|▋         | 169/2500 [01:31<21:08,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 170/2500 [01:32<21:07,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 171/2500 [01:32<21:06,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 172/2500 [01:33<21:05,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 173/2500 [01:33<21:04,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 174/2500 [01:34<21:03,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 175/2500 [01:34<21:02,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 176/2500 [01:35<21:01,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 177/2500 [01:36<21:00,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 178/2500 [01:36<20:59,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 179/2500 [01:37<20:58,  1.84it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 180/2500 [01:37<20:57,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 181/2500 [01:38<20:56,  1.85it/s]loss=0.1732868105173111\n",
      "Epoch 0:   7%|▋         | 182/2500 [01:38<20:55,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 183/2500 [01:39<20:54,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 184/2500 [01:39<20:53,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 185/2500 [01:40<20:52,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   7%|▋         | 186/2500 [01:40<20:51,  1.85it/s]loss=0.17328675091266632\n",
      "Epoch 0:   7%|▋         | 187/2500 [01:41<20:50,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 188/2500 [01:41<20:49,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 189/2500 [01:42<20:48,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 190/2500 [01:42<20:47,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 191/2500 [01:43<20:46,  1.85it/s]loss=0.17328685522079468\n",
      "Epoch 0:   8%|▊         | 192/2500 [01:43<20:45,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 193/2500 [01:44<20:44,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 194/2500 [01:44<20:43,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 195/2500 [01:45<20:42,  1.85it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 196/2500 [01:45<20:41,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 197/2500 [01:46<20:40,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 198/2500 [01:46<20:39,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 199/2500 [01:47<20:38,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 200/2500 [01:47<20:38,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 201/2500 [01:48<20:37,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 202/2500 [01:48<20:36,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 203/2500 [01:49<20:35,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 204/2500 [01:49<20:34,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 205/2500 [01:50<20:33,  1.86it/s]loss=0.17328676581382751\n",
      "Epoch 0:   8%|▊         | 206/2500 [01:50<20:32,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 207/2500 [01:51<20:31,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 208/2500 [01:51<20:30,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 209/2500 [01:52<20:30,  1.86it/s]loss=0.17328712344169617\n",
      "Epoch 0:   8%|▊         | 210/2500 [01:52<20:29,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 211/2500 [01:53<20:28,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   8%|▊         | 212/2500 [01:53<20:27,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▊         | 213/2500 [01:54<20:26,  1.86it/s]loss=0.173287034034729\n",
      "Epoch 0:   9%|▊         | 214/2500 [01:54<20:25,  1.86it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▊         | 215/2500 [01:55<20:25,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▊         | 216/2500 [01:55<20:24,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▊         | 217/2500 [01:56<20:23,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▊         | 218/2500 [01:56<20:22,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 219/2500 [01:57<20:21,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 220/2500 [01:57<20:20,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 221/2500 [01:58<20:20,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 222/2500 [01:58<20:19,  1.87it/s]loss=0.1732867807149887\n",
      "Epoch 0:   9%|▉         | 223/2500 [01:59<20:18,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 224/2500 [01:59<20:17,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 225/2500 [02:00<20:16,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 226/2500 [02:00<20:15,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 227/2500 [02:01<20:15,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 228/2500 [02:01<20:14,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 229/2500 [02:02<20:13,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 230/2500 [02:02<20:12,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 231/2500 [02:03<20:11,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 232/2500 [02:03<20:11,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 233/2500 [02:04<20:10,  1.87it/s]loss=0.1732867807149887\n",
      "Epoch 0:   9%|▉         | 234/2500 [02:04<20:09,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 235/2500 [02:05<20:08,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 236/2500 [02:05<20:07,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:   9%|▉         | 237/2500 [02:06<20:06,  1.87it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|▉         | 238/2500 [02:06<20:06,  1.88it/s]loss=0.1732868254184723\n",
      "Epoch 0:  10%|▉         | 239/2500 [02:07<20:05,  1.88it/s]loss=0.17328667640686035\n",
      "Epoch 0:  10%|▉         | 240/2500 [02:07<20:04,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|▉         | 241/2500 [02:08<20:03,  1.88it/s]loss=0.1732867807149887\n",
      "Epoch 0:  10%|▉         | 242/2500 [02:08<20:02,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|▉         | 243/2500 [02:09<20:02,  1.88it/s]loss=0.17328596115112305\n",
      "Epoch 0:  10%|▉         | 244/2500 [02:09<20:01,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|▉         | 245/2500 [02:10<20:00,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|▉         | 246/2500 [02:10<19:59,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|▉         | 247/2500 [02:11<19:59,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|▉         | 248/2500 [02:11<19:58,  1.88it/s]loss=0.1732868105173111\n",
      "Epoch 0:  10%|▉         | 249/2500 [02:12<19:57,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|█         | 250/2500 [02:12<19:56,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|█         | 251/2500 [02:13<19:55,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|█         | 252/2500 [02:13<19:55,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|█         | 253/2500 [02:14<19:54,  1.88it/s]loss=0.1732868254184723\n",
      "Epoch 0:  10%|█         | 254/2500 [02:14<19:53,  1.88it/s]loss=0.1732868254184723\n",
      "Epoch 0:  10%|█         | 255/2500 [02:15<19:52,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|█         | 256/2500 [02:15<19:52,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|█         | 257/2500 [02:16<19:51,  1.88it/s]loss=0.17328673601150513\n",
      "Epoch 0:  10%|█         | 258/2500 [02:16<19:50,  1.88it/s]loss=0.17328712344169617\n",
      "Epoch 0:  10%|█         | 259/2500 [02:17<19:49,  1.88it/s]loss=0.17328667640686035\n",
      "Epoch 0:  10%|█         | 260/2500 [02:18<19:49,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|█         | 261/2500 [02:18<19:48,  1.88it/s]loss=0.1732867956161499\n",
      "Epoch 0:  10%|█         | 262/2500 [02:19<19:47,  1.88it/s]loss=0.17328687012195587\n",
      "Epoch 0:  11%|█         | 263/2500 [02:19<19:46,  1.88it/s]loss=0.1732870191335678\n",
      "Epoch 0:  11%|█         | 264/2500 [02:20<19:46,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 265/2500 [02:20<19:45,  1.89it/s]loss=0.1732868254184723\n",
      "Epoch 0:  11%|█         | 266/2500 [02:21<19:44,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 267/2500 [02:21<19:43,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 268/2500 [02:22<19:43,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 269/2500 [02:22<19:42,  1.89it/s]loss=0.17328692972660065\n",
      "Epoch 0:  11%|█         | 270/2500 [02:23<19:41,  1.89it/s]loss=0.17328675091266632\n",
      "Epoch 0:  11%|█         | 271/2500 [02:23<19:41,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 272/2500 [02:24<19:40,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 273/2500 [02:24<19:39,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 274/2500 [02:25<19:38,  1.89it/s]loss=0.17328667640686035\n",
      "Epoch 0:  11%|█         | 275/2500 [02:25<19:38,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 276/2500 [02:26<19:37,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 277/2500 [02:26<19:36,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 278/2500 [02:27<19:36,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█         | 279/2500 [02:27<19:35,  1.89it/s]loss=0.17328676581382751\n",
      "Epoch 0:  11%|█         | 280/2500 [02:28<19:34,  1.89it/s]loss=0.17328664660453796\n",
      "Epoch 0:  11%|█         | 281/2500 [02:28<19:33,  1.89it/s]loss=0.17328676581382751\n",
      "Epoch 0:  11%|█▏        | 282/2500 [02:29<19:33,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█▏        | 283/2500 [02:29<19:32,  1.89it/s]loss=0.1732867807149887\n",
      "Epoch 0:  11%|█▏        | 284/2500 [02:30<19:31,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█▏        | 285/2500 [02:30<19:31,  1.89it/s]loss=0.17328676581382751\n",
      "Epoch 0:  11%|█▏        | 286/2500 [02:31<19:30,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  11%|█▏        | 287/2500 [02:31<19:29,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 288/2500 [02:32<19:29,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 289/2500 [02:32<19:28,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 290/2500 [02:33<19:27,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 291/2500 [02:33<19:26,  1.89it/s]loss=0.17328673601150513\n",
      "Epoch 0:  12%|█▏        | 292/2500 [02:34<19:26,  1.89it/s]loss=0.1732865869998932\n",
      "Epoch 0:  12%|█▏        | 293/2500 [02:34<19:25,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 294/2500 [02:35<19:24,  1.89it/s]loss=0.1732868105173111\n",
      "Epoch 0:  12%|█▏        | 295/2500 [02:35<19:24,  1.89it/s]loss=0.1732868105173111\n",
      "Epoch 0:  12%|█▏        | 296/2500 [02:36<19:23,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 297/2500 [02:36<19:22,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 298/2500 [02:37<19:22,  1.89it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 299/2500 [02:37<19:21,  1.90it/s]loss=0.17328676581382751\n",
      "Epoch 0:  12%|█▏        | 300/2500 [02:38<19:20,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 301/2500 [02:38<19:20,  1.90it/s]loss=0.1732867807149887\n",
      "Epoch 0:  12%|█▏        | 302/2500 [02:39<19:19,  1.90it/s]loss=0.173287034034729\n",
      "Epoch 0:  12%|█▏        | 303/2500 [02:39<19:18,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 304/2500 [02:40<19:18,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 305/2500 [02:40<19:17,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 306/2500 [02:41<19:16,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 307/2500 [02:41<19:16,  1.90it/s]loss=0.17328673601150513\n",
      "Epoch 0:  12%|█▏        | 308/2500 [02:42<19:15,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 309/2500 [02:42<19:14,  1.90it/s]loss=0.17328666150569916\n",
      "Epoch 0:  12%|█▏        | 310/2500 [02:43<19:14,  1.90it/s]loss=0.1732867807149887\n",
      "Epoch 0:  12%|█▏        | 311/2500 [02:43<19:13,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  12%|█▏        | 312/2500 [02:44<19:12,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 313/2500 [02:44<19:12,  1.90it/s]loss=0.17328672111034393\n",
      "Epoch 0:  13%|█▎        | 314/2500 [02:45<19:11,  1.90it/s]loss=0.17328676581382751\n",
      "Epoch 0:  13%|█▎        | 315/2500 [02:45<19:10,  1.90it/s]loss=0.17328688502311707\n",
      "Epoch 0:  13%|█▎        | 316/2500 [02:46<19:10,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 317/2500 [02:46<19:09,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 318/2500 [02:47<19:08,  1.90it/s]loss=0.17328676581382751\n",
      "Epoch 0:  13%|█▎        | 319/2500 [02:47<19:08,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 320/2500 [02:48<19:07,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 321/2500 [02:48<19:06,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 322/2500 [02:49<19:06,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 323/2500 [02:49<19:05,  1.90it/s]loss=0.1732868254184723\n",
      "Epoch 0:  13%|█▎        | 324/2500 [02:50<19:04,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 325/2500 [02:50<19:04,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 326/2500 [02:51<19:03,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 327/2500 [02:51<19:02,  1.90it/s]loss=0.1732867807149887\n",
      "Epoch 0:  13%|█▎        | 328/2500 [02:52<19:02,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 329/2500 [02:52<19:01,  1.90it/s]loss=0.17328691482543945\n",
      "Epoch 0:  13%|█▎        | 330/2500 [02:53<19:00,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 331/2500 [02:53<19:00,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 332/2500 [02:54<18:59,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 333/2500 [02:55<18:58,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 334/2500 [02:55<18:58,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 335/2500 [02:56<18:57,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 336/2500 [02:56<18:56,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  13%|█▎        | 337/2500 [02:57<18:56,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▎        | 338/2500 [02:57<18:55,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▎        | 339/2500 [02:58<18:54,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▎        | 340/2500 [02:58<18:54,  1.90it/s]loss=0.17328675091266632\n",
      "Epoch 0:  14%|█▎        | 341/2500 [02:59<18:53,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▎        | 342/2500 [02:59<18:52,  1.90it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▎        | 343/2500 [03:00<18:52,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 344/2500 [03:00<18:51,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 345/2500 [03:01<18:50,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 346/2500 [03:01<18:50,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 347/2500 [03:02<18:49,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 348/2500 [03:02<18:49,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 349/2500 [03:03<18:48,  1.91it/s]loss=0.17328676581382751\n",
      "Epoch 0:  14%|█▍        | 350/2500 [03:03<18:47,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 351/2500 [03:04<18:47,  1.91it/s]loss=0.1732867807149887\n",
      "Epoch 0:  14%|█▍        | 352/2500 [03:04<18:46,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 353/2500 [03:05<18:45,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 354/2500 [03:05<18:45,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 355/2500 [03:06<18:44,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 356/2500 [03:06<18:43,  1.91it/s]loss=0.17328676581382751\n",
      "Epoch 0:  14%|█▍        | 357/2500 [03:07<18:43,  1.91it/s]loss=0.17328688502311707\n",
      "Epoch 0:  14%|█▍        | 358/2500 [03:07<18:42,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 359/2500 [03:08<18:41,  1.91it/s]loss=0.17328688502311707\n",
      "Epoch 0:  14%|█▍        | 360/2500 [03:08<18:41,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 361/2500 [03:09<18:40,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  14%|█▍        | 362/2500 [03:09<18:40,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 363/2500 [03:10<18:39,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 364/2500 [03:10<18:38,  1.91it/s]loss=0.1732867807149887\n",
      "Epoch 0:  15%|█▍        | 365/2500 [03:11<18:38,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 366/2500 [03:11<18:37,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 367/2500 [03:12<18:36,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 368/2500 [03:12<18:36,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 369/2500 [03:13<18:35,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 370/2500 [03:13<18:35,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 371/2500 [03:14<18:34,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 372/2500 [03:14<18:33,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▍        | 373/2500 [03:15<18:33,  1.91it/s]loss=0.17328685522079468\n",
      "Epoch 0:  15%|█▍        | 374/2500 [03:15<18:32,  1.91it/s]loss=0.17328684031963348\n",
      "Epoch 0:  15%|█▌        | 375/2500 [03:16<18:31,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▌        | 376/2500 [03:16<18:31,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▌        | 377/2500 [03:17<18:30,  1.91it/s]loss=0.1732868254184723\n",
      "Epoch 0:  15%|█▌        | 378/2500 [03:17<18:30,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▌        | 379/2500 [03:18<18:29,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▌        | 380/2500 [03:18<18:28,  1.91it/s]loss=0.1732870638370514\n",
      "Epoch 0:  15%|█▌        | 381/2500 [03:19<18:28,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▌        | 382/2500 [03:19<18:27,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▌        | 383/2500 [03:20<18:26,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▌        | 384/2500 [03:20<18:26,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▌        | 385/2500 [03:21<18:25,  1.91it/s]loss=0.1732868254184723\n",
      "Epoch 0:  15%|█▌        | 386/2500 [03:21<18:25,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  15%|█▌        | 387/2500 [03:22<18:24,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 388/2500 [03:22<18:23,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 389/2500 [03:23<18:23,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 390/2500 [03:23<18:22,  1.91it/s]loss=0.1732868105173111\n",
      "Epoch 0:  16%|█▌        | 391/2500 [03:24<18:22,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 392/2500 [03:24<18:21,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 393/2500 [03:25<18:20,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 394/2500 [03:25<18:20,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 395/2500 [03:26<18:19,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 396/2500 [03:26<18:19,  1.91it/s]loss=0.1732868105173111\n",
      "Epoch 0:  16%|█▌        | 397/2500 [03:27<18:18,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 398/2500 [03:27<18:17,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 399/2500 [03:28<18:17,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 400/2500 [03:28<18:16,  1.91it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 401/2500 [03:29<18:16,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 402/2500 [03:29<18:15,  1.92it/s]loss=0.1732867807149887\n",
      "Epoch 0:  16%|█▌        | 403/2500 [03:30<18:14,  1.92it/s]loss=0.17328676581382751\n",
      "Epoch 0:  16%|█▌        | 404/2500 [03:30<18:14,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▌        | 405/2500 [03:31<18:13,  1.92it/s]loss=0.17328692972660065\n",
      "Epoch 0:  16%|█▌        | 406/2500 [03:31<18:13,  1.92it/s]loss=0.1732868105173111\n",
      "Epoch 0:  16%|█▋        | 407/2500 [03:32<18:12,  1.92it/s]loss=0.1732868105173111\n",
      "Epoch 0:  16%|█▋        | 408/2500 [03:32<18:11,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▋        | 409/2500 [03:33<18:11,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▋        | 410/2500 [03:33<18:10,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▋        | 411/2500 [03:34<18:09,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  16%|█▋        | 412/2500 [03:34<18:09,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 413/2500 [03:35<18:08,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 414/2500 [03:35<18:08,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 415/2500 [03:36<18:07,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 416/2500 [03:36<18:07,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 417/2500 [03:37<18:06,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 418/2500 [03:37<18:05,  1.92it/s]loss=0.17328676581382751\n",
      "Epoch 0:  17%|█▋        | 419/2500 [03:38<18:05,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 420/2500 [03:39<18:04,  1.92it/s]loss=0.1732868105173111\n",
      "Epoch 0:  17%|█▋        | 421/2500 [03:39<18:03,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 422/2500 [03:40<18:03,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 423/2500 [03:40<18:02,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 424/2500 [03:41<18:02,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 425/2500 [03:41<18:01,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 426/2500 [03:42<18:01,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 427/2500 [03:42<18:00,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 428/2500 [03:43<17:59,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 429/2500 [03:43<17:59,  1.92it/s]loss=0.17328691482543945\n",
      "Epoch 0:  17%|█▋        | 430/2500 [03:44<17:58,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 431/2500 [03:44<17:58,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 432/2500 [03:45<17:57,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 433/2500 [03:45<17:56,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 434/2500 [03:46<17:56,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 435/2500 [03:46<17:55,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 436/2500 [03:47<17:55,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  17%|█▋        | 437/2500 [03:47<17:54,  1.92it/s]loss=0.17328676581382751\n",
      "Epoch 0:  18%|█▊        | 438/2500 [03:48<17:53,  1.92it/s]loss=0.1732868254184723\n",
      "Epoch 0:  18%|█▊        | 439/2500 [03:48<17:53,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 440/2500 [03:49<17:52,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 441/2500 [03:49<17:52,  1.92it/s]loss=0.1732868254184723\n",
      "Epoch 0:  18%|█▊        | 442/2500 [03:50<17:51,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 443/2500 [03:50<17:50,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 444/2500 [03:51<17:50,  1.92it/s]loss=0.17328676581382751\n",
      "Epoch 0:  18%|█▊        | 445/2500 [03:51<17:49,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 446/2500 [03:52<17:49,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 447/2500 [03:52<17:48,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 448/2500 [03:53<17:48,  1.92it/s]loss=0.17328649759292603\n",
      "Epoch 0:  18%|█▊        | 449/2500 [03:53<17:47,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 450/2500 [03:54<17:46,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 451/2500 [03:54<17:46,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 452/2500 [03:55<17:45,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 453/2500 [03:55<17:45,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 454/2500 [03:56<17:44,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 455/2500 [03:56<17:43,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 456/2500 [03:57<17:43,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 457/2500 [03:57<17:42,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 458/2500 [03:58<17:42,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 459/2500 [03:58<17:41,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 460/2500 [03:59<17:40,  1.92it/s]loss=0.17328685522079468\n",
      "Epoch 0:  18%|█▊        | 461/2500 [03:59<17:40,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  18%|█▊        | 462/2500 [04:00<17:39,  1.92it/s]loss=0.173287034034729\n",
      "Epoch 0:  19%|█▊        | 463/2500 [04:00<17:39,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▊        | 464/2500 [04:01<17:38,  1.92it/s]loss=0.17328670620918274\n",
      "Epoch 0:  19%|█▊        | 465/2500 [04:01<17:38,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▊        | 466/2500 [04:02<17:37,  1.92it/s]loss=0.1732868254184723\n",
      "Epoch 0:  19%|█▊        | 467/2500 [04:02<17:36,  1.92it/s]loss=0.17328611016273499\n",
      "Epoch 0:  19%|█▊        | 468/2500 [04:03<17:36,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 469/2500 [04:03<17:35,  1.92it/s]loss=0.17328672111034393\n",
      "Epoch 0:  19%|█▉        | 470/2500 [04:04<17:35,  1.92it/s]loss=0.1732868254184723\n",
      "Epoch 0:  19%|█▉        | 471/2500 [04:04<17:34,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 472/2500 [04:05<17:34,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 473/2500 [04:05<17:33,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 474/2500 [04:06<17:32,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 475/2500 [04:06<17:32,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 476/2500 [04:07<17:31,  1.92it/s]loss=0.1732867807149887\n",
      "Epoch 0:  19%|█▉        | 477/2500 [04:07<17:31,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 478/2500 [04:08<17:30,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 479/2500 [04:08<17:30,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 480/2500 [04:09<17:29,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 481/2500 [04:09<17:28,  1.92it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 482/2500 [04:10<17:28,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 483/2500 [04:10<17:27,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 484/2500 [04:11<17:27,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 485/2500 [04:11<17:26,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 486/2500 [04:12<17:25,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  19%|█▉        | 487/2500 [04:12<17:25,  1.93it/s]loss=0.17328692972660065\n",
      "Epoch 0:  20%|█▉        | 488/2500 [04:13<17:24,  1.93it/s]loss=0.1732868105173111\n",
      "Epoch 0:  20%|█▉        | 489/2500 [04:13<17:24,  1.93it/s]loss=0.17328684031963348\n",
      "Epoch 0:  20%|█▉        | 490/2500 [04:14<17:23,  1.93it/s]loss=0.1732868254184723\n",
      "Epoch 0:  20%|█▉        | 491/2500 [04:14<17:23,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|█▉        | 492/2500 [04:15<17:22,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|█▉        | 493/2500 [04:15<17:21,  1.93it/s]loss=0.17328694462776184\n",
      "Epoch 0:  20%|█▉        | 494/2500 [04:16<17:21,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|█▉        | 495/2500 [04:16<17:20,  1.93it/s]loss=0.1732868105173111\n",
      "Epoch 0:  20%|█▉        | 496/2500 [04:17<17:20,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|█▉        | 497/2500 [04:17<17:19,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|█▉        | 498/2500 [04:18<17:19,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|█▉        | 499/2500 [04:18<17:18,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|██        | 500/2500 [04:19<17:17,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|██        | 501/2500 [04:19<17:17,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|██        | 502/2500 [04:20<17:16,  1.93it/s]loss=0.1732867807149887\n",
      "Epoch 0:  20%|██        | 503/2500 [04:20<17:16,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|██        | 504/2500 [04:21<17:15,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|██        | 505/2500 [04:22<17:15,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|██        | 506/2500 [04:22<17:14,  1.93it/s]loss=0.17328670620918274\n",
      "Epoch 0:  20%|██        | 507/2500 [04:23<17:13,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|██        | 508/2500 [04:23<17:13,  1.93it/s]loss=0.17328673601150513\n",
      "Epoch 0:  20%|██        | 509/2500 [04:24<17:12,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|██        | 510/2500 [04:24<17:12,  1.93it/s]loss=0.1732868254184723\n",
      "Epoch 0:  20%|██        | 511/2500 [04:25<17:11,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  20%|██        | 512/2500 [04:25<17:11,  1.93it/s]loss=0.17328685522079468\n",
      "Epoch 0:  21%|██        | 513/2500 [04:26<17:10,  1.93it/s]loss=0.1732867807149887\n",
      "Epoch 0:  21%|██        | 514/2500 [04:26<17:09,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 515/2500 [04:27<17:09,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 516/2500 [04:27<17:08,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 517/2500 [04:28<17:08,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 518/2500 [04:28<17:07,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 519/2500 [04:29<17:07,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 520/2500 [04:29<17:06,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 521/2500 [04:30<17:05,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 522/2500 [04:30<17:05,  1.93it/s]loss=0.1732867807149887\n",
      "Epoch 0:  21%|██        | 523/2500 [04:31<17:04,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 524/2500 [04:31<17:04,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 525/2500 [04:32<17:03,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 526/2500 [04:32<17:03,  1.93it/s]loss=0.1732867807149887\n",
      "Epoch 0:  21%|██        | 527/2500 [04:33<17:02,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 528/2500 [04:33<17:02,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 529/2500 [04:34<17:01,  1.93it/s]loss=0.17328672111034393\n",
      "Epoch 0:  21%|██        | 530/2500 [04:34<17:00,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██        | 531/2500 [04:35<17:00,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██▏       | 532/2500 [04:35<16:59,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██▏       | 533/2500 [04:36<16:59,  1.93it/s]loss=0.1732868105173111\n",
      "Epoch 0:  21%|██▏       | 534/2500 [04:36<16:58,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  21%|██▏       | 535/2500 [04:37<16:58,  1.93it/s]loss=0.1732868105173111\n",
      "Epoch 0:  21%|██▏       | 536/2500 [04:37<16:57,  1.93it/s]loss=0.17328672111034393\n",
      "Epoch 0:  21%|██▏       | 537/2500 [04:38<16:57,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 538/2500 [04:38<16:56,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 539/2500 [04:39<16:55,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 540/2500 [04:39<16:55,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 541/2500 [04:40<16:54,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 542/2500 [04:40<16:54,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 543/2500 [04:41<16:53,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 544/2500 [04:41<16:53,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 545/2500 [04:42<16:52,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 546/2500 [04:42<16:51,  1.93it/s]loss=0.17328688502311707\n",
      "Epoch 0:  22%|██▏       | 547/2500 [04:43<16:51,  1.93it/s]loss=0.1732868254184723\n",
      "Epoch 0:  22%|██▏       | 548/2500 [04:43<16:50,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 549/2500 [04:44<16:50,  1.93it/s]loss=0.1732868254184723\n",
      "Epoch 0:  22%|██▏       | 550/2500 [04:44<16:49,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 551/2500 [04:45<16:49,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 552/2500 [04:45<16:48,  1.93it/s]loss=0.1732867807149887\n",
      "Epoch 0:  22%|██▏       | 553/2500 [04:46<16:48,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 554/2500 [04:46<16:47,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 555/2500 [04:47<16:46,  1.93it/s]loss=0.1732868105173111\n",
      "Epoch 0:  22%|██▏       | 556/2500 [04:47<16:46,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 557/2500 [04:48<16:45,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 558/2500 [04:48<16:45,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 559/2500 [04:49<16:44,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 560/2500 [04:49<16:44,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 561/2500 [04:50<16:43,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  22%|██▏       | 562/2500 [04:50<16:43,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 563/2500 [04:51<16:42,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 564/2500 [04:51<16:41,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 565/2500 [04:52<16:41,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 566/2500 [04:52<16:40,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 567/2500 [04:53<16:40,  1.93it/s]loss=0.1732867807149887\n",
      "Epoch 0:  23%|██▎       | 568/2500 [04:53<16:39,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 569/2500 [04:54<16:39,  1.93it/s]loss=0.17328670620918274\n",
      "Epoch 0:  23%|██▎       | 570/2500 [04:54<16:38,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 571/2500 [04:55<16:38,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 572/2500 [04:55<16:37,  1.93it/s]loss=0.17328676581382751\n",
      "Epoch 0:  23%|██▎       | 573/2500 [04:56<16:36,  1.93it/s]loss=0.17328685522079468\n",
      "Epoch 0:  23%|██▎       | 574/2500 [04:56<16:36,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 575/2500 [04:57<16:35,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 576/2500 [04:57<16:35,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 577/2500 [04:58<16:34,  1.93it/s]loss=0.1732868254184723\n",
      "Epoch 0:  23%|██▎       | 578/2500 [04:58<16:34,  1.93it/s]loss=0.1732867807149887\n",
      "Epoch 0:  23%|██▎       | 579/2500 [04:59<16:33,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 580/2500 [05:00<16:33,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 581/2500 [05:00<16:32,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 582/2500 [05:01<16:32,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 583/2500 [05:01<16:31,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 584/2500 [05:02<16:30,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 585/2500 [05:02<16:30,  1.93it/s]loss=0.1732868254184723\n",
      "Epoch 0:  23%|██▎       | 586/2500 [05:03<16:29,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  23%|██▎       | 587/2500 [05:03<16:29,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▎       | 588/2500 [05:04<16:28,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▎       | 589/2500 [05:04<16:28,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▎       | 590/2500 [05:05<16:27,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▎       | 591/2500 [05:05<16:27,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▎       | 592/2500 [05:06<16:26,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▎       | 593/2500 [05:06<16:25,  1.93it/s]loss=0.17328688502311707\n",
      "Epoch 0:  24%|██▍       | 594/2500 [05:07<16:25,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 595/2500 [05:07<16:24,  1.93it/s]loss=0.17328676581382751\n",
      "Epoch 0:  24%|██▍       | 596/2500 [05:08<16:24,  1.93it/s]loss=0.17328673601150513\n",
      "Epoch 0:  24%|██▍       | 597/2500 [05:08<16:23,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 598/2500 [05:09<16:23,  1.93it/s]loss=0.1732867807149887\n",
      "Epoch 0:  24%|██▍       | 599/2500 [05:09<16:22,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 600/2500 [05:10<16:22,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 601/2500 [05:10<16:21,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 602/2500 [05:11<16:21,  1.93it/s]loss=0.1732875555753708\n",
      "Epoch 0:  24%|██▍       | 603/2500 [05:11<16:20,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 604/2500 [05:12<16:19,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 605/2500 [05:12<16:19,  1.93it/s]loss=0.1732868105173111\n",
      "Epoch 0:  24%|██▍       | 606/2500 [05:13<16:18,  1.93it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 607/2500 [05:13<16:18,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 608/2500 [05:14<16:17,  1.94it/s]loss=0.1732868105173111\n",
      "Epoch 0:  24%|██▍       | 609/2500 [05:14<16:17,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  24%|██▍       | 610/2500 [05:15<16:16,  1.94it/s]loss=0.17328625917434692\n",
      "Epoch 0:  24%|██▍       | 611/2500 [05:15<16:16,  1.94it/s]loss=0.17328685522079468\n",
      "Epoch 0:  24%|██▍       | 612/2500 [05:16<16:15,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 613/2500 [05:16<16:15,  1.94it/s]loss=0.1732868254184723\n",
      "Epoch 0:  25%|██▍       | 614/2500 [05:17<16:14,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 615/2500 [05:17<16:13,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 616/2500 [05:18<16:13,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 617/2500 [05:18<16:12,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 618/2500 [05:19<16:12,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 619/2500 [05:19<16:11,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 620/2500 [05:20<16:11,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 621/2500 [05:20<16:10,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 622/2500 [05:21<16:10,  1.94it/s]loss=0.1732868254184723\n",
      "Epoch 0:  25%|██▍       | 623/2500 [05:21<16:09,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▍       | 624/2500 [05:22<16:08,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 625/2500 [05:22<16:08,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 626/2500 [05:23<16:07,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 627/2500 [05:23<16:07,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 628/2500 [05:24<16:06,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 629/2500 [05:24<16:06,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 630/2500 [05:25<16:05,  1.94it/s]loss=0.1732868105173111\n",
      "Epoch 0:  25%|██▌       | 631/2500 [05:25<16:05,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 632/2500 [05:26<16:04,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 633/2500 [05:26<16:04,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 634/2500 [05:27<16:03,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 635/2500 [05:27<16:02,  1.94it/s]loss=0.1732868254184723\n",
      "Epoch 0:  25%|██▌       | 636/2500 [05:28<16:02,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  25%|██▌       | 637/2500 [05:28<16:01,  1.94it/s]loss=0.17328684031963348\n",
      "Epoch 0:  26%|██▌       | 638/2500 [05:29<16:01,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 639/2500 [05:29<16:00,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 640/2500 [05:30<16:00,  1.94it/s]loss=0.1732867807149887\n",
      "Epoch 0:  26%|██▌       | 641/2500 [05:30<15:59,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 642/2500 [05:31<15:59,  1.94it/s]loss=0.17328669130802155\n",
      "Epoch 0:  26%|██▌       | 643/2500 [05:31<15:58,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 644/2500 [05:32<15:58,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 645/2500 [05:32<15:57,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 646/2500 [05:33<15:56,  1.94it/s]loss=0.17328676581382751\n",
      "Epoch 0:  26%|██▌       | 647/2500 [05:33<15:56,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 648/2500 [05:34<15:55,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 649/2500 [05:34<15:55,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 650/2500 [05:35<15:54,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 651/2500 [05:35<15:54,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 652/2500 [05:36<15:53,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 653/2500 [05:36<15:53,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 654/2500 [05:37<15:52,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 655/2500 [05:38<15:52,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▌       | 656/2500 [05:38<15:51,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▋       | 657/2500 [05:39<15:51,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▋       | 658/2500 [05:39<15:50,  1.94it/s]loss=0.17328618466854095\n",
      "Epoch 0:  26%|██▋       | 659/2500 [05:40<15:49,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▋       | 660/2500 [05:40<15:49,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  26%|██▋       | 661/2500 [05:41<15:48,  1.94it/s]loss=0.17328675091266632\n",
      "Epoch 0:  26%|██▋       | 662/2500 [05:41<15:48,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 663/2500 [05:42<15:47,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 664/2500 [05:42<15:47,  1.94it/s]loss=0.17328685522079468\n",
      "Epoch 0:  27%|██▋       | 665/2500 [05:43<15:46,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 666/2500 [05:43<15:46,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 667/2500 [05:44<15:45,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 668/2500 [05:44<15:45,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 669/2500 [05:45<15:44,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 670/2500 [05:45<15:43,  1.94it/s]loss=0.17328667640686035\n",
      "Epoch 0:  27%|██▋       | 671/2500 [05:46<15:43,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 672/2500 [05:46<15:42,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 673/2500 [05:47<15:42,  1.94it/s]loss=0.1732868254184723\n",
      "Epoch 0:  27%|██▋       | 674/2500 [05:47<15:41,  1.94it/s]loss=0.17328664660453796\n",
      "Epoch 0:  27%|██▋       | 675/2500 [05:48<15:41,  1.94it/s]loss=0.1732867807149887\n",
      "Epoch 0:  27%|██▋       | 676/2500 [05:48<15:40,  1.94it/s]loss=0.1732868105173111\n",
      "Epoch 0:  27%|██▋       | 677/2500 [05:49<15:40,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 678/2500 [05:49<15:39,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 679/2500 [05:50<15:39,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 680/2500 [05:50<15:38,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 681/2500 [05:51<15:38,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 682/2500 [05:51<15:37,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 683/2500 [05:52<15:36,  1.94it/s]loss=0.17328685522079468\n",
      "Epoch 0:  27%|██▋       | 684/2500 [05:52<15:36,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 685/2500 [05:53<15:35,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 686/2500 [05:53<15:35,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  27%|██▋       | 687/2500 [05:54<15:34,  1.94it/s]loss=0.17328676581382751\n",
      "Epoch 0:  28%|██▊       | 688/2500 [05:54<15:34,  1.94it/s]loss=0.1732868105173111\n",
      "Epoch 0:  28%|██▊       | 689/2500 [05:55<15:33,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 690/2500 [05:55<15:33,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 691/2500 [05:56<15:32,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 692/2500 [05:56<15:32,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 693/2500 [05:57<15:31,  1.94it/s]loss=0.17328673601150513\n",
      "Epoch 0:  28%|██▊       | 694/2500 [05:57<15:30,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 695/2500 [05:58<15:30,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 696/2500 [05:58<15:29,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 697/2500 [05:59<15:29,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 698/2500 [05:59<15:28,  1.94it/s]loss=0.1732867807149887\n",
      "Epoch 0:  28%|██▊       | 699/2500 [06:00<15:28,  1.94it/s]loss=0.17328676581382751\n",
      "Epoch 0:  28%|██▊       | 700/2500 [06:00<15:27,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 701/2500 [06:01<15:27,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 702/2500 [06:01<15:26,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 703/2500 [06:02<15:26,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 704/2500 [06:02<15:25,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 705/2500 [06:03<15:25,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 706/2500 [06:03<15:24,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 707/2500 [06:04<15:23,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 708/2500 [06:04<15:23,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 709/2500 [06:05<15:22,  1.94it/s]loss=0.17328670620918274\n",
      "Epoch 0:  28%|██▊       | 710/2500 [06:05<15:22,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  28%|██▊       | 711/2500 [06:06<15:21,  1.94it/s]loss=0.1732868254184723\n",
      "Epoch 0:  28%|██▊       | 712/2500 [06:06<15:21,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▊       | 713/2500 [06:07<15:20,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▊       | 714/2500 [06:07<15:20,  1.94it/s]loss=0.1732868254184723\n",
      "Epoch 0:  29%|██▊       | 715/2500 [06:08<15:19,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▊       | 716/2500 [06:08<15:19,  1.94it/s]loss=0.1732868254184723\n",
      "Epoch 0:  29%|██▊       | 717/2500 [06:09<15:18,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▊       | 718/2500 [06:09<15:18,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 719/2500 [06:10<15:17,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 720/2500 [06:10<15:16,  1.94it/s]loss=0.17328676581382751\n",
      "Epoch 0:  29%|██▉       | 721/2500 [06:11<15:16,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 722/2500 [06:11<15:15,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 723/2500 [06:12<15:15,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 724/2500 [06:12<15:14,  1.94it/s]loss=0.1732867807149887\n",
      "Epoch 0:  29%|██▉       | 725/2500 [06:13<15:14,  1.94it/s]loss=0.17328664660453796\n",
      "Epoch 0:  29%|██▉       | 726/2500 [06:13<15:13,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 727/2500 [06:14<15:13,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 728/2500 [06:14<15:12,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 729/2500 [06:15<15:12,  1.94it/s]loss=0.17328603565692902\n",
      "Epoch 0:  29%|██▉       | 730/2500 [06:15<15:11,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 731/2500 [06:16<15:11,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 732/2500 [06:16<15:10,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 733/2500 [06:17<15:09,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 734/2500 [06:17<15:09,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  29%|██▉       | 735/2500 [06:18<15:08,  1.94it/s]loss=0.17328676581382751\n",
      "Epoch 0:  29%|██▉       | 736/2500 [06:19<15:08,  1.94it/s]loss=0.17328673601150513\n",
      "Epoch 0:  29%|██▉       | 737/2500 [06:19<15:07,  1.94it/s]loss=0.17328675091266632\n",
      "Epoch 0:  30%|██▉       | 738/2500 [06:20<15:07,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 739/2500 [06:20<15:06,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 740/2500 [06:21<15:06,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 741/2500 [06:21<15:05,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 742/2500 [06:22<15:05,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 743/2500 [06:22<15:04,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 744/2500 [06:23<15:04,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 745/2500 [06:23<15:03,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 746/2500 [06:24<15:03,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 747/2500 [06:24<15:02,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|██▉       | 748/2500 [06:25<15:01,  1.94it/s]loss=0.17328664660453796\n",
      "Epoch 0:  30%|██▉       | 749/2500 [06:25<15:01,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 750/2500 [06:26<15:00,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 751/2500 [06:26<15:00,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 752/2500 [06:27<14:59,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 753/2500 [06:27<14:59,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 754/2500 [06:28<14:58,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 755/2500 [06:28<14:58,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 756/2500 [06:29<14:57,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 757/2500 [06:29<14:57,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 758/2500 [06:30<14:56,  1.94it/s]loss=0.1732867807149887\n",
      "Epoch 0:  30%|███       | 759/2500 [06:30<14:56,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 760/2500 [06:31<14:55,  1.94it/s]loss=0.17328666150569916\n",
      "Epoch 0:  30%|███       | 761/2500 [06:31<14:54,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  30%|███       | 762/2500 [06:32<14:54,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 763/2500 [06:32<14:53,  1.94it/s]loss=0.17328673601150513\n",
      "Epoch 0:  31%|███       | 764/2500 [06:33<14:53,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 765/2500 [06:33<14:52,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 766/2500 [06:34<14:52,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 767/2500 [06:34<14:51,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 768/2500 [06:35<14:51,  1.94it/s]loss=0.17328676581382751\n",
      "Epoch 0:  31%|███       | 769/2500 [06:35<14:50,  1.94it/s]loss=0.1732868254184723\n",
      "Epoch 0:  31%|███       | 770/2500 [06:36<14:50,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 771/2500 [06:36<14:49,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 772/2500 [06:37<14:49,  1.94it/s]loss=0.17328670620918274\n",
      "Epoch 0:  31%|███       | 773/2500 [06:37<14:48,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 774/2500 [06:38<14:48,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 775/2500 [06:38<14:47,  1.94it/s]loss=0.17328676581382751\n",
      "Epoch 0:  31%|███       | 776/2500 [06:39<14:47,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 777/2500 [06:39<14:46,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 778/2500 [06:40<14:45,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 779/2500 [06:40<14:45,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 780/2500 [06:41<14:44,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███       | 781/2500 [06:41<14:44,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███▏      | 782/2500 [06:42<14:43,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███▏      | 783/2500 [06:42<14:43,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███▏      | 784/2500 [06:43<14:42,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███▏      | 785/2500 [06:43<14:42,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  31%|███▏      | 786/2500 [06:44<14:41,  1.94it/s]loss=0.1732868254184723\n",
      "Epoch 0:  31%|███▏      | 787/2500 [06:44<14:41,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 788/2500 [06:45<14:40,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 789/2500 [06:45<14:40,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 790/2500 [06:46<14:39,  1.94it/s]loss=0.1732867807149887\n",
      "Epoch 0:  32%|███▏      | 791/2500 [06:46<14:39,  1.94it/s]loss=0.1732865869998932\n",
      "Epoch 0:  32%|███▏      | 792/2500 [06:47<14:38,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 793/2500 [06:47<14:38,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 794/2500 [06:48<14:37,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 795/2500 [06:48<14:36,  1.94it/s]loss=0.17328673601150513\n",
      "Epoch 0:  32%|███▏      | 796/2500 [06:49<14:36,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 797/2500 [06:49<14:35,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 798/2500 [06:50<14:35,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 799/2500 [06:50<14:34,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 800/2500 [06:51<14:34,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 801/2500 [06:51<14:33,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 802/2500 [06:52<14:33,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 803/2500 [06:52<14:32,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 804/2500 [06:53<14:32,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 805/2500 [06:53<14:31,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 806/2500 [06:54<14:31,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 807/2500 [06:54<14:30,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 808/2500 [06:55<14:30,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 809/2500 [06:55<14:29,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 810/2500 [06:56<14:28,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 811/2500 [06:57<14:28,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  32%|███▏      | 812/2500 [06:57<14:27,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 813/2500 [06:58<14:27,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 814/2500 [06:58<14:26,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 815/2500 [06:59<14:26,  1.94it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 816/2500 [06:59<14:25,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 817/2500 [07:00<14:25,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 818/2500 [07:00<14:24,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 819/2500 [07:01<14:24,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 820/2500 [07:01<14:23,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 821/2500 [07:02<14:23,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 822/2500 [07:02<14:22,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 823/2500 [07:03<14:22,  1.95it/s]loss=0.17328688502311707\n",
      "Epoch 0:  33%|███▎      | 824/2500 [07:03<14:21,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 825/2500 [07:04<14:21,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 826/2500 [07:04<14:20,  1.95it/s]loss=0.17328663170337677\n",
      "Epoch 0:  33%|███▎      | 827/2500 [07:05<14:19,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 828/2500 [07:05<14:19,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 829/2500 [07:06<14:18,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 830/2500 [07:06<14:18,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 831/2500 [07:07<14:17,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 832/2500 [07:07<14:17,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 833/2500 [07:08<14:16,  1.95it/s]loss=0.17328684031963348\n",
      "Epoch 0:  33%|███▎      | 834/2500 [07:08<14:16,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 835/2500 [07:09<14:15,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  33%|███▎      | 836/2500 [07:09<14:15,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  33%|███▎      | 837/2500 [07:10<14:14,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▎      | 838/2500 [07:10<14:14,  1.95it/s]loss=0.17328684031963348\n",
      "Epoch 0:  34%|███▎      | 839/2500 [07:11<14:13,  1.95it/s]loss=0.1732870638370514\n",
      "Epoch 0:  34%|███▎      | 840/2500 [07:11<14:13,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▎      | 841/2500 [07:12<14:12,  1.95it/s]loss=0.17328695952892303\n",
      "Epoch 0:  34%|███▎      | 842/2500 [07:12<14:12,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▎      | 843/2500 [07:13<14:11,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 844/2500 [07:13<14:11,  1.95it/s]loss=0.1732870638370514\n",
      "Epoch 0:  34%|███▍      | 845/2500 [07:14<14:10,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 846/2500 [07:14<14:09,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  34%|███▍      | 847/2500 [07:15<14:09,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  34%|███▍      | 848/2500 [07:15<14:08,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 849/2500 [07:16<14:08,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 850/2500 [07:16<14:07,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 851/2500 [07:17<14:07,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 852/2500 [07:17<14:06,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 853/2500 [07:18<14:06,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 854/2500 [07:18<14:05,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 855/2500 [07:19<14:05,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 856/2500 [07:19<14:04,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 857/2500 [07:20<14:04,  1.95it/s]loss=0.17328669130802155\n",
      "Epoch 0:  34%|███▍      | 858/2500 [07:20<14:03,  1.95it/s]loss=0.17328667640686035\n",
      "Epoch 0:  34%|███▍      | 859/2500 [07:21<14:03,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 860/2500 [07:21<14:02,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  34%|███▍      | 861/2500 [07:22<14:02,  1.95it/s]loss=0.17328676581382751\n",
      "Epoch 0:  34%|███▍      | 862/2500 [07:22<14:01,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▍      | 863/2500 [07:23<14:00,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  35%|███▍      | 864/2500 [07:23<14:00,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▍      | 865/2500 [07:24<13:59,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▍      | 866/2500 [07:24<13:59,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▍      | 867/2500 [07:25<13:58,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▍      | 868/2500 [07:25<13:58,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▍      | 869/2500 [07:26<13:57,  1.95it/s]loss=0.17328676581382751\n",
      "Epoch 0:  35%|███▍      | 870/2500 [07:26<13:57,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▍      | 871/2500 [07:27<13:56,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▍      | 872/2500 [07:27<13:56,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▍      | 873/2500 [07:28<13:55,  1.95it/s]loss=0.17328688502311707\n",
      "Epoch 0:  35%|███▍      | 874/2500 [07:28<13:55,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 875/2500 [07:29<13:54,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 876/2500 [07:29<13:54,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 877/2500 [07:30<13:53,  1.95it/s]loss=0.17328613996505737\n",
      "Epoch 0:  35%|███▌      | 878/2500 [07:30<13:53,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 879/2500 [07:31<13:52,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  35%|███▌      | 880/2500 [07:31<13:51,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 881/2500 [07:32<13:51,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 882/2500 [07:32<13:50,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 883/2500 [07:33<13:50,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 884/2500 [07:33<13:49,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 885/2500 [07:34<13:49,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  35%|███▌      | 886/2500 [07:34<13:48,  1.95it/s]loss=0.17328685522079468\n",
      "Epoch 0:  35%|███▌      | 887/2500 [07:35<13:48,  1.95it/s]loss=0.17328666150569916\n",
      "Epoch 0:  36%|███▌      | 888/2500 [07:35<13:47,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 889/2500 [07:36<13:47,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 890/2500 [07:36<13:46,  1.95it/s]loss=0.17328672111034393\n",
      "Epoch 0:  36%|███▌      | 891/2500 [07:37<13:46,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 892/2500 [07:38<13:45,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  36%|███▌      | 893/2500 [07:38<13:45,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 894/2500 [07:39<13:44,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 895/2500 [07:39<13:44,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  36%|███▌      | 896/2500 [07:40<13:43,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  36%|███▌      | 897/2500 [07:40<13:43,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 898/2500 [07:41<13:42,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 899/2500 [07:41<13:41,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 900/2500 [07:42<13:41,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 901/2500 [07:42<13:40,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 902/2500 [07:43<13:40,  1.95it/s]loss=0.17328670620918274\n",
      "Epoch 0:  36%|███▌      | 903/2500 [07:43<13:39,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 904/2500 [07:44<13:39,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 905/2500 [07:44<13:38,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▌      | 906/2500 [07:45<13:38,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▋      | 907/2500 [07:45<13:37,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▋      | 908/2500 [07:46<13:37,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▋      | 909/2500 [07:46<13:36,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▋      | 910/2500 [07:47<13:36,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  36%|███▋      | 911/2500 [07:47<13:35,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  36%|███▋      | 912/2500 [07:48<13:35,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 913/2500 [07:48<13:34,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 914/2500 [07:49<13:34,  1.95it/s]loss=0.17328591644763947\n",
      "Epoch 0:  37%|███▋      | 915/2500 [07:49<13:33,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 916/2500 [07:50<13:33,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 917/2500 [07:50<13:32,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 918/2500 [07:51<13:31,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 919/2500 [07:51<13:31,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 920/2500 [07:52<13:30,  1.95it/s]loss=0.17328673601150513\n",
      "Epoch 0:  37%|███▋      | 921/2500 [07:52<13:30,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 922/2500 [07:53<13:29,  1.95it/s]loss=0.17328673601150513\n",
      "Epoch 0:  37%|███▋      | 923/2500 [07:53<13:29,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 924/2500 [07:54<13:28,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  37%|███▋      | 925/2500 [07:54<13:28,  1.95it/s]loss=0.17328700423240662\n",
      "Epoch 0:  37%|███▋      | 926/2500 [07:55<13:27,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 927/2500 [07:55<13:27,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 928/2500 [07:56<13:26,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 929/2500 [07:56<13:26,  1.95it/s]loss=0.17328676581382751\n",
      "Epoch 0:  37%|███▋      | 930/2500 [07:57<13:25,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 931/2500 [07:57<13:25,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 932/2500 [07:58<13:24,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 933/2500 [07:58<13:24,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 934/2500 [07:59<13:23,  1.95it/s]loss=0.17328539490699768\n",
      "Epoch 0:  37%|███▋      | 935/2500 [07:59<13:23,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 936/2500 [08:00<13:22,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  37%|███▋      | 937/2500 [08:00<13:22,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 938/2500 [08:01<13:21,  1.95it/s]loss=0.17328664660453796\n",
      "Epoch 0:  38%|███▊      | 939/2500 [08:01<13:20,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 940/2500 [08:02<13:20,  1.95it/s]loss=0.17328685522079468\n",
      "Epoch 0:  38%|███▊      | 941/2500 [08:02<13:19,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 942/2500 [08:03<13:19,  1.95it/s]loss=0.17328667640686035\n",
      "Epoch 0:  38%|███▊      | 943/2500 [08:03<13:18,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  38%|███▊      | 944/2500 [08:04<13:18,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  38%|███▊      | 945/2500 [08:04<13:17,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 946/2500 [08:05<13:17,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 947/2500 [08:05<13:16,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 948/2500 [08:06<13:16,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 949/2500 [08:06<13:15,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 950/2500 [08:07<13:15,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 951/2500 [08:07<13:14,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 952/2500 [08:08<13:14,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 953/2500 [08:08<13:13,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 954/2500 [08:09<13:13,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  38%|███▊      | 955/2500 [08:09<13:12,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 956/2500 [08:10<13:12,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 957/2500 [08:10<13:11,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 958/2500 [08:11<13:11,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 959/2500 [08:11<13:10,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 960/2500 [08:12<13:09,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 961/2500 [08:12<13:09,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  38%|███▊      | 962/2500 [08:13<13:08,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▊      | 963/2500 [08:13<13:08,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  39%|███▊      | 964/2500 [08:14<13:07,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▊      | 965/2500 [08:14<13:07,  1.95it/s]loss=0.17328689992427826\n",
      "Epoch 0:  39%|███▊      | 966/2500 [08:15<13:06,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▊      | 967/2500 [08:16<13:06,  1.95it/s]loss=0.17328691482543945\n",
      "Epoch 0:  39%|███▊      | 968/2500 [08:16<13:05,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 969/2500 [08:17<13:05,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 970/2500 [08:17<13:04,  1.95it/s]loss=0.17328675091266632\n",
      "Epoch 0:  39%|███▉      | 971/2500 [08:18<13:04,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 972/2500 [08:18<13:03,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 973/2500 [08:19<13:03,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 974/2500 [08:19<13:02,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 975/2500 [08:20<13:02,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  39%|███▉      | 976/2500 [08:20<13:01,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 977/2500 [08:21<13:01,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 978/2500 [08:21<13:00,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  39%|███▉      | 979/2500 [08:22<13:00,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 980/2500 [08:22<12:59,  1.95it/s]loss=0.17328673601150513\n",
      "Epoch 0:  39%|███▉      | 981/2500 [08:23<12:58,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 982/2500 [08:23<12:58,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  39%|███▉      | 983/2500 [08:24<12:57,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 984/2500 [08:24<12:57,  1.95it/s]loss=0.17328670620918274\n",
      "Epoch 0:  39%|███▉      | 985/2500 [08:25<12:56,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 986/2500 [08:25<12:56,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  39%|███▉      | 987/2500 [08:26<12:55,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|███▉      | 988/2500 [08:26<12:55,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  40%|███▉      | 989/2500 [08:27<12:54,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|███▉      | 990/2500 [08:27<12:54,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  40%|███▉      | 991/2500 [08:28<12:53,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|███▉      | 992/2500 [08:28<12:53,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  40%|███▉      | 993/2500 [08:29<12:52,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  40%|███▉      | 994/2500 [08:29<12:52,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|███▉      | 995/2500 [08:30<12:51,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|███▉      | 996/2500 [08:30<12:51,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|███▉      | 997/2500 [08:31<12:50,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|███▉      | 998/2500 [08:31<12:50,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|███▉      | 999/2500 [08:32<12:49,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|████      | 1000/2500 [08:32<12:49,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|████      | 1001/2500 [08:33<12:48,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  40%|████      | 1002/2500 [08:33<12:48,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|████      | 1003/2500 [08:34<12:47,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|████      | 1004/2500 [08:34<12:46,  1.95it/s]loss=0.17328646779060364\n",
      "Epoch 0:  40%|████      | 1005/2500 [08:35<12:46,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|████      | 1006/2500 [08:35<12:45,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|████      | 1007/2500 [08:36<12:45,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  40%|████      | 1008/2500 [08:36<12:44,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|████      | 1009/2500 [08:37<12:44,  1.95it/s]loss=0.17328675091266632\n",
      "Epoch 0:  40%|████      | 1010/2500 [08:37<12:43,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|████      | 1011/2500 [08:38<12:43,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  40%|████      | 1012/2500 [08:38<12:42,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1013/2500 [08:39<12:42,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1014/2500 [08:39<12:41,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1015/2500 [08:40<12:41,  1.95it/s]loss=0.17328676581382751\n",
      "Epoch 0:  41%|████      | 1016/2500 [08:40<12:40,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1017/2500 [08:41<12:40,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1018/2500 [08:41<12:39,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1019/2500 [08:42<12:39,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1020/2500 [08:42<12:38,  1.95it/s]loss=0.17328684031963348\n",
      "Epoch 0:  41%|████      | 1021/2500 [08:43<12:38,  1.95it/s]loss=0.17328676581382751\n",
      "Epoch 0:  41%|████      | 1022/2500 [08:43<12:37,  1.95it/s]loss=0.17328675091266632\n",
      "Epoch 0:  41%|████      | 1023/2500 [08:44<12:37,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1024/2500 [08:44<12:36,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1025/2500 [08:45<12:36,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1026/2500 [08:45<12:35,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  41%|████      | 1027/2500 [08:46<12:35,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  41%|████      | 1028/2500 [08:46<12:34,  1.95it/s]loss=0.17328716814517975\n",
      "Epoch 0:  41%|████      | 1029/2500 [08:47<12:33,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1030/2500 [08:47<12:33,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████      | 1031/2500 [08:48<12:32,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████▏     | 1032/2500 [08:48<12:32,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████▏     | 1033/2500 [08:49<12:31,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  41%|████▏     | 1034/2500 [08:49<12:31,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  41%|████▏     | 1035/2500 [08:50<12:30,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████▏     | 1036/2500 [08:50<12:30,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  41%|████▏     | 1037/2500 [08:51<12:29,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1038/2500 [08:51<12:29,  1.95it/s]loss=0.17328667640686035\n",
      "Epoch 0:  42%|████▏     | 1039/2500 [08:52<12:28,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1040/2500 [08:52<12:28,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1041/2500 [08:53<12:27,  1.95it/s]loss=0.17328673601150513\n",
      "Epoch 0:  42%|████▏     | 1042/2500 [08:54<12:27,  1.95it/s]loss=0.17328700423240662\n",
      "Epoch 0:  42%|████▏     | 1043/2500 [08:54<12:26,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  42%|████▏     | 1044/2500 [08:55<12:26,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1045/2500 [08:55<12:25,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1046/2500 [08:56<12:25,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  42%|████▏     | 1047/2500 [08:56<12:24,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1048/2500 [08:57<12:24,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1049/2500 [08:57<12:23,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1050/2500 [08:58<12:23,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  42%|████▏     | 1051/2500 [08:58<12:22,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1052/2500 [08:59<12:22,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1053/2500 [08:59<12:21,  1.95it/s]loss=0.17328676581382751\n",
      "Epoch 0:  42%|████▏     | 1054/2500 [09:00<12:20,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  42%|████▏     | 1055/2500 [09:00<12:20,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1056/2500 [09:01<12:19,  1.95it/s]loss=0.17328694462776184\n",
      "Epoch 0:  42%|████▏     | 1057/2500 [09:01<12:19,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  42%|████▏     | 1058/2500 [09:02<12:18,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  42%|████▏     | 1059/2500 [09:02<12:18,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1060/2500 [09:03<12:17,  1.95it/s]loss=0.17328676581382751\n",
      "Epoch 0:  42%|████▏     | 1061/2500 [09:03<12:17,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  42%|████▏     | 1062/2500 [09:04<12:16,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1063/2500 [09:04<12:16,  1.95it/s]loss=0.17328672111034393\n",
      "Epoch 0:  43%|████▎     | 1064/2500 [09:05<12:15,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1065/2500 [09:05<12:15,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  43%|████▎     | 1066/2500 [09:06<12:14,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1067/2500 [09:06<12:14,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  43%|████▎     | 1068/2500 [09:07<12:13,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1069/2500 [09:07<12:13,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1070/2500 [09:08<12:12,  1.95it/s]loss=0.17328689992427826\n",
      "Epoch 0:  43%|████▎     | 1071/2500 [09:08<12:12,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1072/2500 [09:09<12:11,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  43%|████▎     | 1073/2500 [09:09<12:11,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1074/2500 [09:10<12:10,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1075/2500 [09:10<12:10,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  43%|████▎     | 1076/2500 [09:11<12:09,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1077/2500 [09:11<12:08,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1078/2500 [09:12<12:08,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1079/2500 [09:12<12:07,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1080/2500 [09:13<12:07,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1081/2500 [09:13<12:06,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1082/2500 [09:14<12:06,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1083/2500 [09:14<12:05,  1.95it/s]loss=0.17328660190105438\n",
      "Epoch 0:  43%|████▎     | 1084/2500 [09:15<12:05,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1085/2500 [09:15<12:04,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1086/2500 [09:16<12:04,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  43%|████▎     | 1087/2500 [09:16<12:03,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▎     | 1088/2500 [09:17<12:03,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▎     | 1089/2500 [09:17<12:02,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▎     | 1090/2500 [09:18<12:02,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▎     | 1091/2500 [09:18<12:01,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▎     | 1092/2500 [09:19<12:01,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▎     | 1093/2500 [09:19<12:00,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1094/2500 [09:20<12:00,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1095/2500 [09:20<11:59,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1096/2500 [09:21<11:59,  1.95it/s]loss=0.17328673601150513\n",
      "Epoch 0:  44%|████▍     | 1097/2500 [09:21<11:58,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1098/2500 [09:22<11:58,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  44%|████▍     | 1099/2500 [09:22<11:57,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1100/2500 [09:23<11:57,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1101/2500 [09:23<11:56,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  44%|████▍     | 1102/2500 [09:24<11:55,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1103/2500 [09:24<11:55,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1104/2500 [09:25<11:54,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1105/2500 [09:25<11:54,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1106/2500 [09:26<11:53,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1107/2500 [09:26<11:53,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1108/2500 [09:27<11:52,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1109/2500 [09:27<11:52,  1.95it/s]loss=0.1732867807149887\n",
      "Epoch 0:  44%|████▍     | 1110/2500 [09:28<11:51,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  44%|████▍     | 1111/2500 [09:28<11:51,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  44%|████▍     | 1112/2500 [09:29<11:50,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▍     | 1113/2500 [09:29<11:50,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▍     | 1114/2500 [09:30<11:49,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  45%|████▍     | 1115/2500 [09:30<11:49,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▍     | 1116/2500 [09:31<11:48,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▍     | 1117/2500 [09:31<11:48,  1.95it/s]loss=0.17328661680221558\n",
      "Epoch 0:  45%|████▍     | 1118/2500 [09:32<11:47,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▍     | 1119/2500 [09:33<11:47,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▍     | 1120/2500 [09:33<11:46,  1.95it/s]loss=0.1732870191335678\n",
      "Epoch 0:  45%|████▍     | 1121/2500 [09:34<11:46,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▍     | 1122/2500 [09:34<11:45,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▍     | 1123/2500 [09:35<11:45,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▍     | 1124/2500 [09:35<11:44,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  45%|████▌     | 1125/2500 [09:36<11:44,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▌     | 1126/2500 [09:36<11:43,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▌     | 1127/2500 [09:37<11:43,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▌     | 1128/2500 [09:37<11:42,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  45%|████▌     | 1129/2500 [09:38<11:42,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▌     | 1130/2500 [09:38<11:41,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▌     | 1131/2500 [09:39<11:40,  1.95it/s]loss=0.17328688502311707\n",
      "Epoch 0:  45%|████▌     | 1132/2500 [09:39<11:40,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▌     | 1133/2500 [09:40<11:39,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▌     | 1134/2500 [09:40<11:39,  1.95it/s]loss=0.17328675091266632\n",
      "Epoch 0:  45%|████▌     | 1135/2500 [09:41<11:38,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▌     | 1136/2500 [09:41<11:38,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  45%|████▌     | 1137/2500 [09:42<11:37,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1138/2500 [09:42<11:37,  1.95it/s]loss=0.1732868254184723\n",
      "Epoch 0:  46%|████▌     | 1139/2500 [09:43<11:36,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1140/2500 [09:43<11:36,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1141/2500 [09:44<11:35,  1.95it/s]loss=0.1732868105173111\n",
      "Epoch 0:  46%|████▌     | 1142/2500 [09:44<11:35,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1143/2500 [09:45<11:34,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1144/2500 [09:45<11:34,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1145/2500 [09:46<11:33,  1.95it/s]loss=0.17328673601150513\n",
      "Epoch 0:  46%|████▌     | 1146/2500 [09:46<11:33,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1147/2500 [09:47<11:32,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1148/2500 [09:47<11:32,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1149/2500 [09:48<11:31,  1.95it/s]loss=0.17328694462776184\n",
      "Epoch 0:  46%|████▌     | 1150/2500 [09:48<11:31,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1151/2500 [09:49<11:30,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1152/2500 [09:49<11:30,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1153/2500 [09:50<11:29,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1154/2500 [09:50<11:29,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1155/2500 [09:51<11:28,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▌     | 1156/2500 [09:51<11:27,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▋     | 1157/2500 [09:52<11:27,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▋     | 1158/2500 [09:52<11:26,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▋     | 1159/2500 [09:53<11:26,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▋     | 1160/2500 [09:53<11:25,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  46%|████▋     | 1161/2500 [09:54<11:25,  1.95it/s]loss=0.17328676581382751\n",
      "Epoch 0:  46%|████▋     | 1162/2500 [09:54<11:24,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  47%|████▋     | 1163/2500 [09:55<11:24,  1.95it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1297/2500 [11:03<10:15,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  52%|█████▏    | 1298/2500 [11:03<10:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1299/2500 [11:04<10:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1300/2500 [11:04<10:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1301/2500 [11:05<10:13,  1.96it/s]loss=0.17328672111034393\n",
      "Epoch 0:  52%|█████▏    | 1302/2500 [11:05<10:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1303/2500 [11:06<10:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1304/2500 [11:06<10:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1305/2500 [11:07<10:10,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  52%|█████▏    | 1306/2500 [11:07<10:10,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  52%|█████▏    | 1307/2500 [11:08<10:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1308/2500 [11:08<10:09,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  52%|█████▏    | 1309/2500 [11:09<10:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1310/2500 [11:09<10:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  52%|█████▏    | 1311/2500 [11:10<10:07,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  52%|█████▏    | 1312/2500 [11:10<10:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1313/2500 [11:11<10:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1314/2500 [11:11<10:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1315/2500 [11:12<10:05,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  53%|█████▎    | 1316/2500 [11:12<10:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1317/2500 [11:13<10:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1318/2500 [11:13<10:04,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  53%|█████▎    | 1319/2500 [11:14<10:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1320/2500 [11:14<10:03,  1.96it/s]loss=0.1732865571975708\n",
      "Epoch 0:  53%|█████▎    | 1321/2500 [11:15<10:02,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  53%|█████▎    | 1322/2500 [11:15<10:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1323/2500 [11:16<10:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1324/2500 [11:16<10:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1325/2500 [11:17<10:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1326/2500 [11:17<10:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1327/2500 [11:18<09:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1328/2500 [11:18<09:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1329/2500 [11:19<09:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1330/2500 [11:19<09:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1331/2500 [11:20<09:57,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  53%|█████▎    | 1332/2500 [11:20<09:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1333/2500 [11:21<09:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1334/2500 [11:21<09:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1335/2500 [11:22<09:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1336/2500 [11:22<09:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  53%|█████▎    | 1337/2500 [11:23<09:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▎    | 1338/2500 [11:23<09:53,  1.96it/s]loss=0.17328736186027527\n",
      "Epoch 0:  54%|█████▎    | 1339/2500 [11:24<09:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▎    | 1340/2500 [11:24<09:52,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  54%|█████▎    | 1341/2500 [11:25<09:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▎    | 1342/2500 [11:25<09:51,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  54%|█████▎    | 1343/2500 [11:26<09:51,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  54%|█████▍    | 1344/2500 [11:26<09:50,  1.96it/s]loss=0.17328684031963348\n",
      "Epoch 0:  54%|█████▍    | 1345/2500 [11:27<09:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1346/2500 [11:27<09:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1347/2500 [11:28<09:49,  1.96it/s]loss=0.17328675091266632\n",
      "Epoch 0:  54%|█████▍    | 1348/2500 [11:28<09:48,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  54%|█████▍    | 1349/2500 [11:29<09:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1350/2500 [11:30<09:47,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1351/2500 [11:30<09:47,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1352/2500 [11:31<09:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1353/2500 [11:31<09:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1354/2500 [11:32<09:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1355/2500 [11:32<09:45,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  54%|█████▍    | 1356/2500 [11:33<09:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1357/2500 [11:33<09:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1358/2500 [11:34<09:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1359/2500 [11:34<09:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1360/2500 [11:35<09:42,  1.96it/s]loss=0.173287034034729\n",
      "Epoch 0:  54%|█████▍    | 1361/2500 [11:35<09:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  54%|█████▍    | 1362/2500 [11:36<09:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▍    | 1363/2500 [11:36<09:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▍    | 1364/2500 [11:37<09:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▍    | 1365/2500 [11:37<09:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▍    | 1366/2500 [11:38<09:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▍    | 1367/2500 [11:38<09:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▍    | 1368/2500 [11:39<09:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▍    | 1369/2500 [11:39<09:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▍    | 1370/2500 [11:40<09:37,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  55%|█████▍    | 1371/2500 [11:40<09:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▍    | 1372/2500 [11:41<09:36,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  55%|█████▍    | 1373/2500 [11:41<09:35,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  55%|█████▍    | 1374/2500 [11:42<09:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▌    | 1375/2500 [11:42<09:34,  1.96it/s]loss=0.17328691482543945\n",
      "Epoch 0:  55%|█████▌    | 1376/2500 [11:43<09:34,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  55%|█████▌    | 1377/2500 [11:43<09:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▌    | 1378/2500 [11:44<09:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▌    | 1379/2500 [11:44<09:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▌    | 1380/2500 [11:45<09:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▌    | 1381/2500 [11:45<09:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▌    | 1382/2500 [11:46<09:31,  1.96it/s]loss=0.17328687012195587\n",
      "Epoch 0:  55%|█████▌    | 1383/2500 [11:46<09:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▌    | 1384/2500 [11:47<09:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▌    | 1385/2500 [11:47<09:29,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  55%|█████▌    | 1386/2500 [11:48<09:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  55%|█████▌    | 1387/2500 [11:48<09:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1388/2500 [11:49<09:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1389/2500 [11:49<09:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1390/2500 [11:50<09:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1391/2500 [11:50<09:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1392/2500 [11:51<09:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1393/2500 [11:51<09:25,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  56%|█████▌    | 1394/2500 [11:52<09:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1395/2500 [11:52<09:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1396/2500 [11:53<09:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1397/2500 [11:53<09:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1398/2500 [11:54<09:23,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  56%|█████▌    | 1399/2500 [11:54<09:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1400/2500 [11:55<09:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1401/2500 [11:55<09:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1402/2500 [11:56<09:20,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  56%|█████▌    | 1403/2500 [11:56<09:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1404/2500 [11:57<09:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1405/2500 [11:57<09:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▌    | 1406/2500 [11:58<09:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▋    | 1407/2500 [11:58<09:18,  1.96it/s]loss=0.1732870191335678\n",
      "Epoch 0:  56%|█████▋    | 1408/2500 [11:59<09:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▋    | 1409/2500 [11:59<09:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▋    | 1410/2500 [12:00<09:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▋    | 1411/2500 [12:00<09:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  56%|█████▋    | 1412/2500 [12:01<09:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1413/2500 [12:01<09:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1414/2500 [12:02<09:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1415/2500 [12:02<09:14,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  57%|█████▋    | 1416/2500 [12:03<09:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1417/2500 [12:03<09:13,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  57%|█████▋    | 1418/2500 [12:04<09:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1419/2500 [12:04<09:12,  1.96it/s]loss=0.17328664660453796\n",
      "Epoch 0:  57%|█████▋    | 1420/2500 [12:05<09:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1421/2500 [12:05<09:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1422/2500 [12:06<09:10,  1.96it/s]loss=0.17328667640686035\n",
      "Epoch 0:  57%|█████▋    | 1423/2500 [12:06<09:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1424/2500 [12:07<09:09,  1.96it/s]loss=0.17328675091266632\n",
      "Epoch 0:  57%|█████▋    | 1425/2500 [12:07<09:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1426/2500 [12:08<09:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1427/2500 [12:08<09:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1428/2500 [12:09<09:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1429/2500 [12:09<09:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1430/2500 [12:10<09:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1431/2500 [12:10<09:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1432/2500 [12:11<09:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1433/2500 [12:11<09:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1434/2500 [12:12<09:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1435/2500 [12:12<09:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  57%|█████▋    | 1436/2500 [12:13<09:03,  1.96it/s]loss=0.17328689992427826\n",
      "Epoch 0:  57%|█████▋    | 1437/2500 [12:13<09:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1438/2500 [12:14<09:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1439/2500 [12:15<09:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1440/2500 [12:15<09:01,  1.96it/s]loss=0.17328707873821259\n",
      "Epoch 0:  58%|█████▊    | 1441/2500 [12:16<09:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1442/2500 [12:16<09:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1443/2500 [12:17<08:59,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  58%|█████▊    | 1444/2500 [12:17<08:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1445/2500 [12:18<08:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1446/2500 [12:18<08:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1447/2500 [12:19<08:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1448/2500 [12:19<08:57,  1.96it/s]loss=0.1732870191335678\n",
      "Epoch 0:  58%|█████▊    | 1449/2500 [12:20<08:56,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  58%|█████▊    | 1450/2500 [12:20<08:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1451/2500 [12:21<08:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1452/2500 [12:21<08:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1453/2500 [12:22<08:54,  1.96it/s]loss=0.17328691482543945\n",
      "Epoch 0:  58%|█████▊    | 1454/2500 [12:22<08:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1455/2500 [12:23<08:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1456/2500 [12:23<08:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1457/2500 [12:24<08:52,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  58%|█████▊    | 1458/2500 [12:24<08:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1459/2500 [12:25<08:51,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1460/2500 [12:25<08:51,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1461/2500 [12:26<08:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  58%|█████▊    | 1462/2500 [12:26<08:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▊    | 1463/2500 [12:27<08:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▊    | 1464/2500 [12:27<08:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▊    | 1465/2500 [12:28<08:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▊    | 1466/2500 [12:28<08:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▊    | 1467/2500 [12:29<08:47,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▊    | 1468/2500 [12:29<08:47,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1469/2500 [12:30<08:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1470/2500 [12:30<08:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1471/2500 [12:31<08:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1472/2500 [12:31<08:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1473/2500 [12:32<08:44,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  59%|█████▉    | 1474/2500 [12:32<08:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1475/2500 [12:33<08:43,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  59%|█████▉    | 1476/2500 [12:33<08:42,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  59%|█████▉    | 1477/2500 [12:34<08:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1478/2500 [12:34<08:41,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  59%|█████▉    | 1479/2500 [12:35<08:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1480/2500 [12:35<08:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1481/2500 [12:36<08:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1482/2500 [12:36<08:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1483/2500 [12:37<08:39,  1.96it/s]loss=0.17328669130802155\n",
      "Epoch 0:  59%|█████▉    | 1484/2500 [12:37<08:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1485/2500 [12:38<08:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1486/2500 [12:38<08:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  59%|█████▉    | 1487/2500 [12:39<08:37,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  60%|█████▉    | 1488/2500 [12:39<08:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|█████▉    | 1489/2500 [12:40<08:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|█████▉    | 1490/2500 [12:40<08:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|█████▉    | 1491/2500 [12:41<08:35,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  60%|█████▉    | 1492/2500 [12:41<08:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|█████▉    | 1493/2500 [12:42<08:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|█████▉    | 1494/2500 [12:42<08:33,  1.96it/s]loss=0.17328697443008423\n",
      "Epoch 0:  60%|█████▉    | 1495/2500 [12:43<08:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|█████▉    | 1496/2500 [12:43<08:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|█████▉    | 1497/2500 [12:44<08:32,  1.96it/s]loss=0.17328691482543945\n",
      "Epoch 0:  60%|█████▉    | 1498/2500 [12:44<08:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|█████▉    | 1499/2500 [12:45<08:31,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  60%|██████    | 1500/2500 [12:45<08:30,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  60%|██████    | 1501/2500 [12:46<08:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|██████    | 1502/2500 [12:46<08:29,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  60%|██████    | 1503/2500 [12:47<08:29,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  60%|██████    | 1504/2500 [12:47<08:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|██████    | 1505/2500 [12:48<08:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|██████    | 1506/2500 [12:48<08:27,  1.96it/s]loss=0.1732865869998932\n",
      "Epoch 0:  60%|██████    | 1507/2500 [12:49<08:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|██████    | 1508/2500 [12:49<08:26,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  60%|██████    | 1509/2500 [12:50<08:25,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  60%|██████    | 1510/2500 [12:50<08:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  60%|██████    | 1511/2500 [12:51<08:24,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  60%|██████    | 1512/2500 [12:51<08:24,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  61%|██████    | 1513/2500 [12:52<08:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1514/2500 [12:52<08:23,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  61%|██████    | 1515/2500 [12:53<08:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1516/2500 [12:53<08:22,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  61%|██████    | 1517/2500 [12:54<08:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1518/2500 [12:55<08:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1519/2500 [12:55<08:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1520/2500 [12:56<08:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1521/2500 [12:56<08:19,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  61%|██████    | 1522/2500 [12:57<08:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1523/2500 [12:57<08:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1524/2500 [12:58<08:18,  1.96it/s]loss=0.17328694462776184\n",
      "Epoch 0:  61%|██████    | 1525/2500 [12:58<08:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1526/2500 [12:59<08:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1527/2500 [12:59<08:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1528/2500 [13:00<08:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1529/2500 [13:00<08:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1530/2500 [13:01<08:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████    | 1531/2500 [13:01<08:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████▏   | 1532/2500 [13:02<08:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████▏   | 1533/2500 [13:02<08:13,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  61%|██████▏   | 1534/2500 [13:03<08:13,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  61%|██████▏   | 1535/2500 [13:03<08:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████▏   | 1536/2500 [13:04<08:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  61%|██████▏   | 1537/2500 [13:04<08:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1538/2500 [13:05<08:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1539/2500 [13:05<08:10,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  62%|██████▏   | 1540/2500 [13:06<08:10,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  62%|██████▏   | 1541/2500 [13:06<08:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1542/2500 [13:07<08:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1543/2500 [13:07<08:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1544/2500 [13:08<08:08,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  62%|██████▏   | 1545/2500 [13:08<08:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1546/2500 [13:09<08:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1547/2500 [13:09<08:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1548/2500 [13:10<08:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1549/2500 [13:10<08:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1550/2500 [13:11<08:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1551/2500 [13:11<08:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1552/2500 [13:12<08:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1553/2500 [13:12<08:03,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  62%|██████▏   | 1554/2500 [13:13<08:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1555/2500 [13:13<08:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1556/2500 [13:14<08:01,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  62%|██████▏   | 1557/2500 [13:14<08:01,  1.96it/s]loss=0.17328691482543945\n",
      "Epoch 0:  62%|██████▏   | 1558/2500 [13:15<08:00,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  62%|██████▏   | 1559/2500 [13:15<08:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1560/2500 [13:16<07:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  62%|██████▏   | 1561/2500 [13:16<07:59,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  62%|██████▏   | 1562/2500 [13:17<07:58,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  63%|██████▎   | 1563/2500 [13:17<07:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1564/2500 [13:18<07:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1565/2500 [13:18<07:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1566/2500 [13:19<07:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1567/2500 [13:19<07:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1568/2500 [13:20<07:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1569/2500 [13:20<07:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1570/2500 [13:21<07:54,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  63%|██████▎   | 1571/2500 [13:21<07:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1572/2500 [13:22<07:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1573/2500 [13:22<07:53,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  63%|██████▎   | 1574/2500 [13:23<07:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1575/2500 [13:23<07:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1576/2500 [13:24<07:51,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1577/2500 [13:24<07:51,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1578/2500 [13:25<07:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1579/2500 [13:25<07:50,  1.96it/s]loss=0.17328724265098572\n",
      "Epoch 0:  63%|██████▎   | 1580/2500 [13:26<07:49,  1.96it/s]loss=0.173287034034729\n",
      "Epoch 0:  63%|██████▎   | 1581/2500 [13:26<07:49,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  63%|██████▎   | 1582/2500 [13:27<07:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1583/2500 [13:27<07:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1584/2500 [13:28<07:47,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  63%|██████▎   | 1585/2500 [13:28<07:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1586/2500 [13:29<07:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  63%|██████▎   | 1587/2500 [13:29<07:45,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  64%|██████▎   | 1588/2500 [13:30<07:45,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  64%|██████▎   | 1589/2500 [13:30<07:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▎   | 1590/2500 [13:31<07:44,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  64%|██████▎   | 1591/2500 [13:31<07:43,  1.96it/s]loss=0.17328712344169617\n",
      "Epoch 0:  64%|██████▎   | 1592/2500 [13:32<07:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▎   | 1593/2500 [13:32<07:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1594/2500 [13:33<07:42,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  64%|██████▍   | 1595/2500 [13:33<07:41,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  64%|██████▍   | 1596/2500 [13:34<07:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1597/2500 [13:35<07:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1598/2500 [13:35<07:40,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  64%|██████▍   | 1599/2500 [13:36<07:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1600/2500 [13:36<07:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1601/2500 [13:37<07:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1602/2500 [13:37<07:38,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  64%|██████▍   | 1603/2500 [13:38<07:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1604/2500 [13:38<07:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1605/2500 [13:39<07:36,  1.96it/s]loss=0.17328689992427826\n",
      "Epoch 0:  64%|██████▍   | 1606/2500 [13:39<07:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1607/2500 [13:40<07:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1608/2500 [13:40<07:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1609/2500 [13:41<07:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1610/2500 [13:41<07:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1611/2500 [13:42<07:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  64%|██████▍   | 1612/2500 [13:42<07:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▍   | 1613/2500 [13:43<07:32,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  65%|██████▍   | 1614/2500 [13:43<07:32,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  65%|██████▍   | 1615/2500 [13:44<07:31,  1.96it/s]loss=0.17328694462776184\n",
      "Epoch 0:  65%|██████▍   | 1616/2500 [13:44<07:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▍   | 1617/2500 [13:45<07:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▍   | 1618/2500 [13:45<07:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▍   | 1619/2500 [13:46<07:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▍   | 1620/2500 [13:46<07:29,  1.96it/s]loss=0.17328579723834991\n",
      "Epoch 0:  65%|██████▍   | 1621/2500 [13:47<07:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▍   | 1622/2500 [13:47<07:28,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  65%|██████▍   | 1623/2500 [13:48<07:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▍   | 1624/2500 [13:48<07:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▌   | 1625/2500 [13:49<07:26,  1.96it/s]loss=0.1732865273952484\n",
      "Epoch 0:  65%|██████▌   | 1626/2500 [13:49<07:25,  1.96it/s]loss=0.17328664660453796\n",
      "Epoch 0:  65%|██████▌   | 1627/2500 [13:50<07:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▌   | 1628/2500 [13:50<07:24,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  65%|██████▌   | 1629/2500 [13:51<07:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▌   | 1630/2500 [13:51<07:23,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  65%|██████▌   | 1631/2500 [13:52<07:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▌   | 1632/2500 [13:52<07:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▌   | 1633/2500 [13:53<07:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▌   | 1634/2500 [13:53<07:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▌   | 1635/2500 [13:54<07:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▌   | 1636/2500 [13:54<07:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  65%|██████▌   | 1637/2500 [13:55<07:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1638/2500 [13:55<07:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1639/2500 [13:56<07:19,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  66%|██████▌   | 1640/2500 [13:56<07:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1641/2500 [13:57<07:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1642/2500 [13:57<07:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1643/2500 [13:58<07:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1644/2500 [13:58<07:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1645/2500 [13:59<07:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1646/2500 [13:59<07:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1647/2500 [14:00<07:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1648/2500 [14:00<07:14,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  66%|██████▌   | 1649/2500 [14:01<07:14,  1.96it/s]loss=0.17328687012195587\n",
      "Epoch 0:  66%|██████▌   | 1650/2500 [14:01<07:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1651/2500 [14:02<07:13,  1.96it/s]loss=0.17328667640686035\n",
      "Epoch 0:  66%|██████▌   | 1652/2500 [14:02<07:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1653/2500 [14:03<07:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1654/2500 [14:03<07:11,  1.96it/s]loss=0.17328688502311707\n",
      "Epoch 0:  66%|██████▌   | 1655/2500 [14:04<07:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▌   | 1656/2500 [14:04<07:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▋   | 1657/2500 [14:05<07:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▋   | 1658/2500 [14:05<07:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▋   | 1659/2500 [14:06<07:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▋   | 1660/2500 [14:06<07:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  66%|██████▋   | 1661/2500 [14:07<07:08,  1.96it/s]loss=0.17328694462776184\n",
      "Epoch 0:  66%|██████▋   | 1662/2500 [14:07<07:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1663/2500 [14:08<07:07,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  67%|██████▋   | 1664/2500 [14:08<07:06,  1.96it/s]loss=0.17328687012195587\n",
      "Epoch 0:  67%|██████▋   | 1665/2500 [14:09<07:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1666/2500 [14:09<07:05,  1.96it/s]loss=0.1732870191335678\n",
      "Epoch 0:  67%|██████▋   | 1667/2500 [14:10<07:04,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  67%|██████▋   | 1668/2500 [14:10<07:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1669/2500 [14:11<07:03,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  67%|██████▋   | 1670/2500 [14:11<07:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1671/2500 [14:12<07:02,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  67%|██████▋   | 1672/2500 [14:12<07:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1673/2500 [14:13<07:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1674/2500 [14:13<07:01,  1.96it/s]loss=0.17328691482543945\n",
      "Epoch 0:  67%|██████▋   | 1675/2500 [14:14<07:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1676/2500 [14:15<07:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1677/2500 [14:15<06:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1678/2500 [14:16<06:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1679/2500 [14:16<06:58,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  67%|██████▋   | 1680/2500 [14:17<06:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1681/2500 [14:17<06:57,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  67%|██████▋   | 1682/2500 [14:18<06:57,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  67%|██████▋   | 1683/2500 [14:18<06:56,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  67%|██████▋   | 1684/2500 [14:19<06:56,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  67%|██████▋   | 1685/2500 [14:19<06:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1686/2500 [14:20<06:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  67%|██████▋   | 1687/2500 [14:20<06:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1688/2500 [14:21<06:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1689/2500 [14:21<06:53,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  68%|██████▊   | 1690/2500 [14:22<06:53,  1.96it/s]loss=0.17328687012195587\n",
      "Epoch 0:  68%|██████▊   | 1691/2500 [14:22<06:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1692/2500 [14:23<06:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1693/2500 [14:23<06:51,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1694/2500 [14:24<06:51,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1695/2500 [14:24<06:50,  1.96it/s]loss=0.17328684031963348\n",
      "Epoch 0:  68%|██████▊   | 1696/2500 [14:25<06:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1697/2500 [14:25<06:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1698/2500 [14:26<06:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1699/2500 [14:26<06:48,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  68%|██████▊   | 1700/2500 [14:27<06:48,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  68%|██████▊   | 1701/2500 [14:27<06:47,  1.96it/s]loss=0.17328692972660065\n",
      "Epoch 0:  68%|██████▊   | 1702/2500 [14:28<06:47,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  68%|██████▊   | 1703/2500 [14:28<06:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1704/2500 [14:29<06:46,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  68%|██████▊   | 1705/2500 [14:29<06:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1706/2500 [14:30<06:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1707/2500 [14:30<06:44,  1.96it/s]loss=0.1732865869998932\n",
      "Epoch 0:  68%|██████▊   | 1708/2500 [14:31<06:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1709/2500 [14:31<06:43,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  68%|██████▊   | 1710/2500 [14:32<06:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1711/2500 [14:32<06:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  68%|██████▊   | 1712/2500 [14:33<06:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▊   | 1713/2500 [14:33<06:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▊   | 1714/2500 [14:34<06:40,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  69%|██████▊   | 1715/2500 [14:34<06:40,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  69%|██████▊   | 1716/2500 [14:35<06:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▊   | 1717/2500 [14:35<06:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▊   | 1718/2500 [14:36<06:38,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  69%|██████▉   | 1719/2500 [14:36<06:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1720/2500 [14:37<06:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1721/2500 [14:37<06:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1722/2500 [14:38<06:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1723/2500 [14:38<06:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1724/2500 [14:39<06:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1725/2500 [14:39<06:35,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  69%|██████▉   | 1726/2500 [14:40<06:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1727/2500 [14:40<06:34,  1.96it/s]loss=0.17328687012195587\n",
      "Epoch 0:  69%|██████▉   | 1728/2500 [14:41<06:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1729/2500 [14:41<06:33,  1.96it/s]loss=0.17328684031963348\n",
      "Epoch 0:  69%|██████▉   | 1730/2500 [14:42<06:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1731/2500 [14:42<06:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1732/2500 [14:43<06:31,  1.96it/s]loss=0.17328663170337677\n",
      "Epoch 0:  69%|██████▉   | 1733/2500 [14:43<06:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1734/2500 [14:44<06:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1735/2500 [14:44<06:30,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  69%|██████▉   | 1736/2500 [14:45<06:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  69%|██████▉   | 1737/2500 [14:45<06:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|██████▉   | 1738/2500 [14:46<06:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|██████▉   | 1739/2500 [14:46<06:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|██████▉   | 1740/2500 [14:47<06:27,  1.96it/s]loss=0.17328667640686035\n",
      "Epoch 0:  70%|██████▉   | 1741/2500 [14:47<06:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|██████▉   | 1742/2500 [14:48<06:26,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  70%|██████▉   | 1743/2500 [14:48<06:26,  1.96it/s]loss=0.17328669130802155\n",
      "Epoch 0:  70%|██████▉   | 1744/2500 [14:49<06:25,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  70%|██████▉   | 1745/2500 [14:50<06:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|██████▉   | 1746/2500 [14:50<06:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|██████▉   | 1747/2500 [14:51<06:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|██████▉   | 1748/2500 [14:51<06:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|██████▉   | 1749/2500 [14:52<06:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1750/2500 [14:52<06:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1751/2500 [14:53<06:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1752/2500 [14:53<06:21,  1.96it/s]loss=0.17328675091266632\n",
      "Epoch 0:  70%|███████   | 1753/2500 [14:54<06:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1754/2500 [14:54<06:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1755/2500 [14:55<06:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1756/2500 [14:55<06:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1757/2500 [14:56<06:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1758/2500 [14:56<06:18,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  70%|███████   | 1759/2500 [14:57<06:17,  1.96it/s]loss=0.17328667640686035\n",
      "Epoch 0:  70%|███████   | 1760/2500 [14:57<06:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1761/2500 [14:58<06:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  70%|███████   | 1762/2500 [14:58<06:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1763/2500 [14:59<06:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1764/2500 [14:59<06:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1765/2500 [15:00<06:14,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  71%|███████   | 1766/2500 [15:00<06:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1767/2500 [15:01<06:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1768/2500 [15:01<06:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1769/2500 [15:02<06:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1770/2500 [15:02<06:12,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  71%|███████   | 1771/2500 [15:03<06:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1772/2500 [15:03<06:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1773/2500 [15:04<06:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1774/2500 [15:04<06:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1775/2500 [15:05<06:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1776/2500 [15:05<06:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1777/2500 [15:06<06:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1778/2500 [15:06<06:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1779/2500 [15:07<06:07,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  71%|███████   | 1780/2500 [15:07<06:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████   | 1781/2500 [15:08<06:06,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  71%|███████▏  | 1782/2500 [15:08<06:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████▏  | 1783/2500 [15:09<06:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████▏  | 1784/2500 [15:09<06:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████▏  | 1785/2500 [15:10<06:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████▏  | 1786/2500 [15:10<06:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  71%|███████▏  | 1787/2500 [15:11<06:03,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  72%|███████▏  | 1788/2500 [15:11<06:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1789/2500 [15:12<06:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1790/2500 [15:12<06:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1791/2500 [15:13<06:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1792/2500 [15:13<06:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1793/2500 [15:14<06:00,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  72%|███████▏  | 1794/2500 [15:14<06:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1795/2500 [15:15<05:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1796/2500 [15:15<05:58,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  72%|███████▏  | 1797/2500 [15:16<05:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1798/2500 [15:16<05:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1799/2500 [15:17<05:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1800/2500 [15:17<05:56,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  72%|███████▏  | 1801/2500 [15:18<05:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1802/2500 [15:18<05:55,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  72%|███████▏  | 1803/2500 [15:19<05:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1804/2500 [15:19<05:54,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  72%|███████▏  | 1805/2500 [15:20<05:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1806/2500 [15:20<05:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1807/2500 [15:21<05:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1808/2500 [15:21<05:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1809/2500 [15:22<05:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  72%|███████▏  | 1810/2500 [15:22<05:51,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  72%|███████▏  | 1811/2500 [15:23<05:51,  1.96it/s]loss=0.17328667640686035\n",
      "Epoch 0:  72%|███████▏  | 1812/2500 [15:23<05:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1813/2500 [15:24<05:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1814/2500 [15:24<05:49,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  73%|███████▎  | 1815/2500 [15:25<05:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1816/2500 [15:25<05:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1817/2500 [15:26<05:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1818/2500 [15:26<05:47,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  73%|███████▎  | 1819/2500 [15:27<05:47,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  73%|███████▎  | 1820/2500 [15:27<05:46,  1.96it/s]loss=0.17328691482543945\n",
      "Epoch 0:  73%|███████▎  | 1821/2500 [15:28<05:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1822/2500 [15:29<05:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1823/2500 [15:29<05:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1824/2500 [15:30<05:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1825/2500 [15:30<05:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1826/2500 [15:31<05:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1827/2500 [15:31<05:43,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  73%|███████▎  | 1828/2500 [15:32<05:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1829/2500 [15:32<05:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1830/2500 [15:33<05:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1831/2500 [15:33<05:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1832/2500 [15:34<05:40,  1.96it/s]loss=0.17328688502311707\n",
      "Epoch 0:  73%|███████▎  | 1833/2500 [15:34<05:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1834/2500 [15:35<05:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1835/2500 [15:35<05:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1836/2500 [15:36<05:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  73%|███████▎  | 1837/2500 [15:36<05:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▎  | 1838/2500 [15:37<05:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▎  | 1839/2500 [15:37<05:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▎  | 1840/2500 [15:38<05:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▎  | 1841/2500 [15:38<05:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▎  | 1842/2500 [15:39<05:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▎  | 1843/2500 [15:39<05:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1844/2500 [15:40<05:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1845/2500 [15:40<05:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1846/2500 [15:41<05:33,  1.96it/s]loss=0.17328661680221558\n",
      "Epoch 0:  74%|███████▍  | 1847/2500 [15:41<05:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1848/2500 [15:42<05:32,  1.96it/s]loss=0.17328675091266632\n",
      "Epoch 0:  74%|███████▍  | 1849/2500 [15:42<05:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1850/2500 [15:43<05:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1851/2500 [15:43<05:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1852/2500 [15:44<05:30,  1.96it/s]loss=0.17328661680221558\n",
      "Epoch 0:  74%|███████▍  | 1853/2500 [15:44<05:29,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  74%|███████▍  | 1854/2500 [15:45<05:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1855/2500 [15:45<05:28,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  74%|███████▍  | 1856/2500 [15:46<05:28,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  74%|███████▍  | 1857/2500 [15:46<05:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1858/2500 [15:47<05:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1859/2500 [15:47<05:26,  1.96it/s]loss=0.17328684031963348\n",
      "Epoch 0:  74%|███████▍  | 1860/2500 [15:48<05:26,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  74%|███████▍  | 1861/2500 [15:48<05:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  74%|███████▍  | 1862/2500 [15:49<05:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  75%|███████▍  | 1863/2500 [15:49<05:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  75%|███████▍  | 1864/2500 [15:50<05:24,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  75%|███████▍  | 1865/2500 [15:50<05:23,  1.96it/s]loss=0.17328689992427826\n",
      "Epoch 0:  78%|███████▊  | 1959/2500 [16:38<04:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  78%|███████▊  | 1960/2500 [16:38<04:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  78%|███████▊  | 1961/2500 [16:39<04:34,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  78%|███████▊  | 1962/2500 [16:39<04:34,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  79%|███████▊  | 1963/2500 [16:40<04:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▊  | 1964/2500 [16:40<04:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▊  | 1965/2500 [16:41<04:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▊  | 1966/2500 [16:41<04:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▊  | 1967/2500 [16:42<04:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▊  | 1968/2500 [16:42<04:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1969/2500 [16:43<04:30,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  79%|███████▉  | 1970/2500 [16:43<04:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1971/2500 [16:44<04:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1972/2500 [16:44<04:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1973/2500 [16:45<04:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1974/2500 [16:45<04:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1975/2500 [16:46<04:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1976/2500 [16:46<04:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1977/2500 [16:47<04:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1978/2500 [16:47<04:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1979/2500 [16:48<04:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1980/2500 [16:48<04:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1981/2500 [16:49<04:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1982/2500 [16:50<04:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1983/2500 [16:50<04:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1984/2500 [16:51<04:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1985/2500 [16:51<04:22,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  79%|███████▉  | 1986/2500 [16:52<04:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  79%|███████▉  | 1987/2500 [16:52<04:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|███████▉  | 1988/2500 [16:53<04:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|███████▉  | 1989/2500 [16:53<04:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|███████▉  | 1990/2500 [16:54<04:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|███████▉  | 1991/2500 [16:54<04:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|███████▉  | 1992/2500 [16:55<04:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|███████▉  | 1993/2500 [16:55<04:18,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  80%|███████▉  | 1994/2500 [16:56<04:17,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  80%|███████▉  | 1995/2500 [16:56<04:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|███████▉  | 1996/2500 [16:57<04:16,  1.96it/s]loss=0.17328688502311707\n",
      "Epoch 0:  80%|███████▉  | 1997/2500 [16:57<04:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|███████▉  | 1998/2500 [16:58<04:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|███████▉  | 1999/2500 [16:58<04:15,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  80%|████████  | 2000/2500 [16:59<04:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|████████  | 2001/2500 [16:59<04:14,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  80%|████████  | 2002/2500 [17:00<04:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|████████  | 2003/2500 [17:00<04:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|████████  | 2004/2500 [17:01<04:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|████████  | 2005/2500 [17:01<04:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|████████  | 2006/2500 [17:02<04:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|████████  | 2007/2500 [17:02<04:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|████████  | 2008/2500 [17:03<04:10,  1.96it/s]loss=0.17328684031963348\n",
      "Epoch 0:  80%|████████  | 2009/2500 [17:03<04:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|████████  | 2010/2500 [17:04<04:09,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  80%|████████  | 2011/2500 [17:04<04:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  80%|████████  | 2012/2500 [17:05<04:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2013/2500 [17:05<04:08,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  81%|████████  | 2014/2500 [17:06<04:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2015/2500 [17:06<04:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2016/2500 [17:07<04:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2017/2500 [17:07<04:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2018/2500 [17:08<04:05,  1.96it/s]loss=0.17328590154647827\n",
      "Epoch 0:  81%|████████  | 2019/2500 [17:08<04:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2020/2500 [17:09<04:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2021/2500 [17:09<04:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2022/2500 [17:10<04:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2023/2500 [17:10<04:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2024/2500 [17:11<04:02,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  81%|████████  | 2025/2500 [17:11<04:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2026/2500 [17:12<04:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2027/2500 [17:12<04:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2028/2500 [17:13<04:00,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  81%|████████  | 2029/2500 [17:13<03:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████  | 2030/2500 [17:14<03:59,  1.96it/s]loss=0.17328675091266632\n",
      "Epoch 0:  81%|████████  | 2031/2500 [17:14<03:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████▏ | 2032/2500 [17:15<03:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████▏ | 2033/2500 [17:15<03:57,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  81%|████████▏ | 2034/2500 [17:16<03:57,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  81%|████████▏ | 2035/2500 [17:16<03:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  81%|████████▏ | 2036/2500 [17:17<03:56,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  81%|████████▏ | 2037/2500 [17:17<03:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2038/2500 [17:18<03:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2039/2500 [17:18<03:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2040/2500 [17:19<03:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2041/2500 [17:19<03:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2042/2500 [17:20<03:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2043/2500 [17:20<03:52,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  82%|████████▏ | 2044/2500 [17:21<03:52,  1.96it/s]loss=0.17328697443008423\n",
      "Epoch 0:  82%|████████▏ | 2045/2500 [17:21<03:51,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2046/2500 [17:22<03:51,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  82%|████████▏ | 2047/2500 [17:22<03:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2048/2500 [17:23<03:50,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  82%|████████▏ | 2049/2500 [17:23<03:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2050/2500 [17:24<03:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2051/2500 [17:24<03:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2052/2500 [17:25<03:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2053/2500 [17:25<03:47,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  82%|████████▏ | 2054/2500 [17:26<03:47,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  82%|████████▏ | 2055/2500 [17:26<03:46,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  82%|████████▏ | 2056/2500 [17:27<03:46,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  82%|████████▏ | 2057/2500 [17:27<03:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2058/2500 [17:28<03:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2059/2500 [17:28<03:44,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  82%|████████▏ | 2060/2500 [17:29<03:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2061/2500 [17:29<03:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  82%|████████▏ | 2062/2500 [17:30<03:43,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  83%|████████▎ | 2063/2500 [17:30<03:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2064/2500 [17:31<03:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2065/2500 [17:31<03:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2066/2500 [17:32<03:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2067/2500 [17:33<03:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2068/2500 [17:33<03:40,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  83%|████████▎ | 2069/2500 [17:34<03:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2070/2500 [17:34<03:39,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  83%|████████▎ | 2071/2500 [17:35<03:38,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  83%|████████▎ | 2072/2500 [17:35<03:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2073/2500 [17:36<03:37,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  83%|████████▎ | 2074/2500 [17:36<03:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2075/2500 [17:37<03:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2076/2500 [17:37<03:35,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  83%|████████▎ | 2077/2500 [17:38<03:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2078/2500 [17:38<03:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2079/2500 [17:39<03:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2080/2500 [17:39<03:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2081/2500 [17:40<03:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2082/2500 [17:40<03:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2083/2500 [17:41<03:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2084/2500 [17:41<03:31,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  83%|████████▎ | 2085/2500 [17:42<03:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  83%|████████▎ | 2086/2500 [17:42<03:30,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  83%|████████▎ | 2087/2500 [17:43<03:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▎ | 2088/2500 [17:43<03:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▎ | 2089/2500 [17:44<03:29,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  84%|████████▎ | 2090/2500 [17:44<03:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▎ | 2091/2500 [17:45<03:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▎ | 2092/2500 [17:45<03:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▎ | 2093/2500 [17:46<03:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2094/2500 [17:46<03:26,  1.96it/s]loss=0.173286572098732\n",
      "Epoch 0:  84%|████████▍ | 2095/2500 [17:47<03:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2096/2500 [17:47<03:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2097/2500 [17:48<03:25,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  84%|████████▍ | 2098/2500 [17:48<03:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2099/2500 [17:49<03:24,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  84%|████████▍ | 2100/2500 [17:49<03:23,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  84%|████████▍ | 2101/2500 [17:50<03:23,  1.96it/s]loss=0.1732870191335678\n",
      "Epoch 0:  84%|████████▍ | 2102/2500 [17:50<03:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2103/2500 [17:51<03:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2104/2500 [17:51<03:21,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  84%|████████▍ | 2105/2500 [17:52<03:21,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  84%|████████▍ | 2106/2500 [17:52<03:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2107/2500 [17:53<03:20,  1.96it/s]loss=0.17328688502311707\n",
      "Epoch 0:  84%|████████▍ | 2108/2500 [17:53<03:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2109/2500 [17:54<03:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2110/2500 [17:54<03:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2111/2500 [17:55<03:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  84%|████████▍ | 2112/2500 [17:55<03:17,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  85%|████████▍ | 2113/2500 [17:56<03:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▍ | 2114/2500 [17:56<03:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▍ | 2115/2500 [17:57<03:16,  1.96it/s]loss=0.17328688502311707\n",
      "Epoch 0:  85%|████████▍ | 2116/2500 [17:57<03:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▍ | 2117/2500 [17:58<03:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▍ | 2118/2500 [17:58<03:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▍ | 2119/2500 [17:59<03:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▍ | 2120/2500 [17:59<03:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▍ | 2121/2500 [18:00<03:13,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  85%|████████▍ | 2122/2500 [18:00<03:12,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  85%|████████▍ | 2123/2500 [18:01<03:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▍ | 2124/2500 [18:01<03:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2125/2500 [18:02<03:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2126/2500 [18:02<03:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2127/2500 [18:03<03:09,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  85%|████████▌ | 2128/2500 [18:03<03:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2129/2500 [18:04<03:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2130/2500 [18:04<03:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2131/2500 [18:05<03:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2132/2500 [18:05<03:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2133/2500 [18:06<03:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2134/2500 [18:06<03:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2135/2500 [18:07<03:05,  1.96it/s]loss=0.173287034034729\n",
      "Epoch 0:  85%|████████▌ | 2136/2500 [18:07<03:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  85%|████████▌ | 2137/2500 [18:08<03:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2138/2500 [18:08<03:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2139/2500 [18:09<03:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2140/2500 [18:09<03:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2141/2500 [18:10<03:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2142/2500 [18:10<03:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2143/2500 [18:11<03:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2144/2500 [18:11<03:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2145/2500 [18:12<03:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2146/2500 [18:12<03:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2147/2500 [18:13<02:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2148/2500 [18:13<02:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2149/2500 [18:14<02:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2150/2500 [18:15<02:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2151/2500 [18:15<02:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2152/2500 [18:16<02:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2153/2500 [18:16<02:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2154/2500 [18:17<02:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▌ | 2155/2500 [18:17<02:55,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  86%|████████▌ | 2156/2500 [18:18<02:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▋ | 2157/2500 [18:18<02:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▋ | 2158/2500 [18:19<02:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▋ | 2159/2500 [18:19<02:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▋ | 2160/2500 [18:20<02:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▋ | 2161/2500 [18:20<02:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  86%|████████▋ | 2162/2500 [18:21<02:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2163/2500 [18:21<02:51,  1.96it/s]loss=0.17328667640686035\n",
      "Epoch 0:  87%|████████▋ | 2164/2500 [18:22<02:51,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2165/2500 [18:22<02:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2166/2500 [18:23<02:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2167/2500 [18:23<02:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2168/2500 [18:24<02:49,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  87%|████████▋ | 2169/2500 [18:24<02:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2170/2500 [18:25<02:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2171/2500 [18:25<02:47,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2172/2500 [18:26<02:47,  1.96it/s]loss=0.17328688502311707\n",
      "Epoch 0:  87%|████████▋ | 2173/2500 [18:26<02:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2174/2500 [18:27<02:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2175/2500 [18:27<02:45,  1.96it/s]loss=0.17328687012195587\n",
      "Epoch 0:  87%|████████▋ | 2176/2500 [18:28<02:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2177/2500 [18:28<02:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2178/2500 [18:29<02:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2179/2500 [18:29<02:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2180/2500 [18:30<02:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2181/2500 [18:30<02:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2182/2500 [18:31<02:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2183/2500 [18:31<02:41,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  87%|████████▋ | 2184/2500 [18:32<02:40,  1.96it/s]loss=0.17328697443008423\n",
      "Epoch 0:  87%|████████▋ | 2185/2500 [18:32<02:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2186/2500 [18:33<02:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  87%|████████▋ | 2187/2500 [18:33<02:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2188/2500 [18:34<02:38,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  88%|████████▊ | 2189/2500 [18:34<02:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2190/2500 [18:35<02:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2191/2500 [18:35<02:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2192/2500 [18:36<02:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2193/2500 [18:36<02:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2194/2500 [18:37<02:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2195/2500 [18:37<02:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2196/2500 [18:38<02:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2197/2500 [18:38<02:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2198/2500 [18:39<02:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2199/2500 [18:39<02:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2200/2500 [18:40<02:32,  1.96it/s]loss=0.17328664660453796\n",
      "Epoch 0:  88%|████████▊ | 2201/2500 [18:40<02:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2202/2500 [18:41<02:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2203/2500 [18:41<02:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2204/2500 [18:42<02:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2205/2500 [18:42<02:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2206/2500 [18:43<02:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2207/2500 [18:43<02:29,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  88%|████████▊ | 2208/2500 [18:44<02:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2209/2500 [18:44<02:28,  1.96it/s]loss=0.173287034034729\n",
      "Epoch 0:  88%|████████▊ | 2210/2500 [18:45<02:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2211/2500 [18:45<02:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  88%|████████▊ | 2212/2500 [18:46<02:26,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  89%|████████▊ | 2213/2500 [18:46<02:26,  1.96it/s]loss=0.17328669130802155\n",
      "Epoch 0:  89%|████████▊ | 2214/2500 [18:47<02:25,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  89%|████████▊ | 2215/2500 [18:47<02:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▊ | 2216/2500 [18:48<02:24,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  89%|████████▊ | 2217/2500 [18:48<02:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▊ | 2218/2500 [18:49<02:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2219/2500 [18:49<02:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2220/2500 [18:50<02:22,  1.96it/s]loss=0.17328666150569916\n",
      "Epoch 0:  89%|████████▉ | 2221/2500 [18:50<02:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2222/2500 [18:51<02:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2223/2500 [18:51<02:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2224/2500 [18:52<02:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2225/2500 [18:52<02:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2226/2500 [18:53<02:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2227/2500 [18:53<02:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2228/2500 [18:54<02:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2229/2500 [18:54<02:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2230/2500 [18:55<02:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2231/2500 [18:55<02:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2232/2500 [18:56<02:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2233/2500 [18:57<02:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2234/2500 [18:57<02:15,  1.96it/s]loss=0.17328664660453796\n",
      "Epoch 0:  89%|████████▉ | 2235/2500 [18:58<02:14,  1.96it/s]loss=0.17328688502311707\n",
      "Epoch 0:  89%|████████▉ | 2236/2500 [18:58<02:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  89%|████████▉ | 2237/2500 [18:59<02:13,  1.96it/s]loss=0.17328672111034393\n",
      "Epoch 0:  90%|████████▉ | 2238/2500 [18:59<02:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|████████▉ | 2239/2500 [19:00<02:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|████████▉ | 2240/2500 [19:00<02:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|████████▉ | 2241/2500 [19:01<02:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|████████▉ | 2242/2500 [19:01<02:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|████████▉ | 2243/2500 [19:02<02:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|████████▉ | 2244/2500 [19:02<02:10,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  90%|████████▉ | 2245/2500 [19:03<02:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|████████▉ | 2246/2500 [19:03<02:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|████████▉ | 2247/2500 [19:04<02:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|████████▉ | 2248/2500 [19:04<02:08,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  90%|████████▉ | 2249/2500 [19:05<02:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|█████████ | 2250/2500 [19:05<02:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|█████████ | 2251/2500 [19:06<02:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|█████████ | 2252/2500 [19:06<02:06,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  90%|█████████ | 2253/2500 [19:07<02:05,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  90%|█████████ | 2254/2500 [19:07<02:05,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  90%|█████████ | 2255/2500 [19:08<02:04,  1.96it/s]loss=0.17328667640686035\n",
      "Epoch 0:  90%|█████████ | 2256/2500 [19:08<02:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|█████████ | 2257/2500 [19:09<02:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|█████████ | 2258/2500 [19:09<02:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|█████████ | 2259/2500 [19:10<02:02,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  90%|█████████ | 2260/2500 [19:10<02:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|█████████ | 2261/2500 [19:11<02:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  90%|█████████ | 2262/2500 [19:11<02:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2263/2500 [19:12<02:00,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  91%|█████████ | 2264/2500 [19:12<02:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2265/2500 [19:13<01:59,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  91%|█████████ | 2266/2500 [19:13<01:59,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2267/2500 [19:14<01:58,  1.96it/s]loss=0.17328687012195587\n",
      "Epoch 0:  91%|█████████ | 2268/2500 [19:14<01:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2269/2500 [19:15<01:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2270/2500 [19:15<01:57,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  91%|█████████ | 2271/2500 [19:16<01:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2272/2500 [19:16<01:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2273/2500 [19:17<01:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2274/2500 [19:17<01:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2275/2500 [19:18<01:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2276/2500 [19:18<01:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2277/2500 [19:19<01:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2278/2500 [19:19<01:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2279/2500 [19:20<01:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████ | 2280/2500 [19:20<01:52,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  91%|█████████ | 2281/2500 [19:21<01:51,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████▏| 2282/2500 [19:21<01:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████▏| 2283/2500 [19:22<01:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████▏| 2284/2500 [19:22<01:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████▏| 2285/2500 [19:23<01:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████▏| 2286/2500 [19:23<01:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  91%|█████████▏| 2287/2500 [19:24<01:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2288/2500 [19:24<01:47,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2289/2500 [19:25<01:47,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  92%|█████████▏| 2290/2500 [19:25<01:46,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  92%|█████████▏| 2291/2500 [19:26<01:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2292/2500 [19:26<01:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2293/2500 [19:27<01:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2294/2500 [19:27<01:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2295/2500 [19:28<01:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2296/2500 [19:28<01:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2297/2500 [19:29<01:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2298/2500 [19:29<01:42,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2299/2500 [19:30<01:42,  1.96it/s]loss=0.17328615486621857\n",
      "Epoch 0:  92%|█████████▏| 2300/2500 [19:30<01:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2301/2500 [19:31<01:41,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  92%|█████████▏| 2302/2500 [19:31<01:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2303/2500 [19:32<01:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2304/2500 [19:33<01:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2305/2500 [19:33<01:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2306/2500 [19:34<01:38,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2307/2500 [19:34<01:38,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  92%|█████████▏| 2308/2500 [19:35<01:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2309/2500 [19:35<01:37,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2310/2500 [19:36<01:36,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  92%|█████████▏| 2311/2500 [19:36<01:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  92%|█████████▏| 2312/2500 [19:37<01:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2313/2500 [19:37<01:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2314/2500 [19:38<01:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2315/2500 [19:38<01:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2316/2500 [19:39<01:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2317/2500 [19:39<01:33,  1.96it/s]loss=0.17328649759292603\n",
      "Epoch 0:  93%|█████████▎| 2318/2500 [19:40<01:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2319/2500 [19:40<01:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2320/2500 [19:41<01:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2321/2500 [19:41<01:31,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  93%|█████████▎| 2322/2500 [19:42<01:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2323/2500 [19:42<01:30,  1.96it/s]loss=0.17328660190105438\n",
      "Epoch 0:  93%|█████████▎| 2324/2500 [19:43<01:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2325/2500 [19:43<01:29,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  93%|█████████▎| 2326/2500 [19:44<01:28,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  93%|█████████▎| 2327/2500 [19:44<01:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2328/2500 [19:45<01:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2329/2500 [19:45<01:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2330/2500 [19:46<01:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2331/2500 [19:46<01:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2332/2500 [19:47<01:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2333/2500 [19:47<01:25,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  93%|█████████▎| 2334/2500 [19:48<01:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2335/2500 [19:48<01:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  93%|█████████▎| 2336/2500 [19:49<01:23,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  93%|█████████▎| 2337/2500 [19:49<01:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▎| 2338/2500 [19:50<01:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▎| 2339/2500 [19:50<01:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▎| 2340/2500 [19:51<01:21,  1.96it/s]loss=0.17328687012195587\n",
      "Epoch 0:  94%|█████████▎| 2341/2500 [19:51<01:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▎| 2342/2500 [19:52<01:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▎| 2343/2500 [19:52<01:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2344/2500 [19:53<01:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2345/2500 [19:53<01:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2346/2500 [19:54<01:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2347/2500 [19:54<01:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2348/2500 [19:55<01:17,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  94%|█████████▍| 2349/2500 [19:55<01:16,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  94%|█████████▍| 2350/2500 [19:56<01:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2351/2500 [19:56<01:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2352/2500 [19:57<01:15,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2353/2500 [19:57<01:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2354/2500 [19:58<01:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2355/2500 [19:58<01:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2356/2500 [19:59<01:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2357/2500 [19:59<01:12,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  94%|█████████▍| 2358/2500 [20:00<01:12,  1.96it/s]loss=0.17328692972660065\n",
      "Epoch 0:  94%|█████████▍| 2359/2500 [20:00<01:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2360/2500 [20:01<01:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2361/2500 [20:01<01:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  94%|█████████▍| 2362/2500 [20:02<01:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▍| 2363/2500 [20:02<01:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▍| 2364/2500 [20:03<01:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▍| 2365/2500 [20:03<01:08,  1.96it/s]loss=0.17328664660453796\n",
      "Epoch 0:  95%|█████████▍| 2366/2500 [20:04<01:08,  1.96it/s]loss=0.17328715324401855\n",
      "Epoch 0:  95%|█████████▍| 2367/2500 [20:04<01:07,  1.96it/s]loss=0.17328666150569916\n",
      "Epoch 0:  95%|█████████▍| 2368/2500 [20:05<01:07,  1.96it/s]loss=0.17328675091266632\n",
      "Epoch 0:  95%|█████████▍| 2369/2500 [20:05<01:06,  1.96it/s]loss=0.1732863485813141\n",
      "Epoch 0:  95%|█████████▍| 2370/2500 [20:06<01:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▍| 2371/2500 [20:06<01:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▍| 2372/2500 [20:07<01:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▍| 2373/2500 [20:07<01:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▍| 2374/2500 [20:08<01:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▌| 2375/2500 [20:09<01:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▌| 2376/2500 [20:09<01:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▌| 2377/2500 [20:10<01:02,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  95%|█████████▌| 2378/2500 [20:10<01:02,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  95%|█████████▌| 2379/2500 [20:11<01:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▌| 2380/2500 [20:11<01:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▌| 2381/2500 [20:12<01:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▌| 2382/2500 [20:12<01:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▌| 2383/2500 [20:13<00:59,  1.96it/s]loss=0.17328684031963348\n",
      "Epoch 0:  95%|█████████▌| 2384/2500 [20:13<00:59,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  95%|█████████▌| 2385/2500 [20:14<00:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▌| 2386/2500 [20:14<00:58,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  95%|█████████▌| 2387/2500 [20:15<00:57,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  96%|█████████▌| 2388/2500 [20:15<00:57,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2389/2500 [20:16<00:56,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2390/2500 [20:16<00:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2391/2500 [20:17<00:55,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2392/2500 [20:17<00:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2393/2500 [20:18<00:54,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2394/2500 [20:18<00:53,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  96%|█████████▌| 2395/2500 [20:19<00:53,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2396/2500 [20:19<00:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2397/2500 [20:20<00:52,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2398/2500 [20:20<00:51,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  96%|█████████▌| 2399/2500 [20:21<00:51,  1.96it/s]loss=0.17328664660453796\n",
      "Epoch 0:  96%|█████████▌| 2400/2500 [20:21<00:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2401/2500 [20:22<00:50,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2402/2500 [20:22<00:49,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  96%|█████████▌| 2403/2500 [20:23<00:49,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2404/2500 [20:23<00:48,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▌| 2405/2500 [20:24<00:48,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  96%|█████████▌| 2406/2500 [20:24<00:47,  1.96it/s]loss=0.17328691482543945\n",
      "Epoch 0:  96%|█████████▋| 2407/2500 [20:25<00:47,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▋| 2408/2500 [20:25<00:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▋| 2409/2500 [20:26<00:46,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▋| 2410/2500 [20:26<00:45,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  96%|█████████▋| 2411/2500 [20:27<00:45,  1.96it/s]loss=0.17328685522079468\n",
      "Epoch 0:  96%|█████████▋| 2412/2500 [20:27<00:44,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  97%|█████████▋| 2413/2500 [20:28<00:44,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2414/2500 [20:28<00:43,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  97%|█████████▋| 2415/2500 [20:29<00:43,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2416/2500 [20:29<00:42,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  97%|█████████▋| 2417/2500 [20:30<00:42,  1.96it/s]loss=0.17328646779060364\n",
      "Epoch 0:  97%|█████████▋| 2418/2500 [20:30<00:41,  1.96it/s]loss=0.17328697443008423\n",
      "Epoch 0:  97%|█████████▋| 2419/2500 [20:31<00:41,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2420/2500 [20:31<00:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2421/2500 [20:32<00:40,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2422/2500 [20:32<00:39,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  97%|█████████▋| 2423/2500 [20:33<00:39,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2424/2500 [20:33<00:38,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  97%|█████████▋| 2425/2500 [20:34<00:38,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  97%|█████████▋| 2426/2500 [20:34<00:37,  1.96it/s]loss=0.1732865571975708\n",
      "Epoch 0:  97%|█████████▋| 2427/2500 [20:35<00:37,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  97%|█████████▋| 2428/2500 [20:35<00:36,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2429/2500 [20:36<00:36,  1.96it/s]loss=0.17328687012195587\n",
      "Epoch 0:  97%|█████████▋| 2430/2500 [20:36<00:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2431/2500 [20:37<00:35,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2432/2500 [20:37<00:34,  1.96it/s]loss=0.17328670620918274\n",
      "Epoch 0:  97%|█████████▋| 2433/2500 [20:38<00:34,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2434/2500 [20:38<00:33,  1.96it/s]loss=0.17328661680221558\n",
      "Epoch 0:  97%|█████████▋| 2435/2500 [20:39<00:33,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  97%|█████████▋| 2436/2500 [20:39<00:32,  1.96it/s]loss=0.1732872873544693\n",
      "Epoch 0:  97%|█████████▋| 2437/2500 [20:40<00:32,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2438/2500 [20:40<00:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2439/2500 [20:41<00:31,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2440/2500 [20:41<00:30,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2441/2500 [20:42<00:30,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  98%|█████████▊| 2442/2500 [20:42<00:29,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  98%|█████████▊| 2443/2500 [20:43<00:29,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2444/2500 [20:43<00:28,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2445/2500 [20:44<00:27,  1.96it/s]loss=0.1732867807149887\n",
      "Epoch 0:  98%|█████████▊| 2446/2500 [20:45<00:27,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2447/2500 [20:45<00:26,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2448/2500 [20:46<00:26,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  98%|█████████▊| 2449/2500 [20:46<00:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2450/2500 [20:47<00:25,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2451/2500 [20:47<00:24,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  98%|█████████▊| 2452/2500 [20:48<00:24,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2453/2500 [20:48<00:23,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  98%|█████████▊| 2454/2500 [20:49<00:23,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2455/2500 [20:49<00:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2456/2500 [20:50<00:22,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2457/2500 [20:50<00:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2458/2500 [20:51<00:21,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2459/2500 [20:51<00:20,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2460/2500 [20:52<00:20,  1.96it/s]loss=0.17328667640686035\n",
      "Epoch 0:  98%|█████████▊| 2461/2500 [20:52<00:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  98%|█████████▊| 2462/2500 [20:53<00:19,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▊| 2463/2500 [20:53<00:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▊| 2464/2500 [20:54<00:18,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▊| 2465/2500 [20:54<00:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▊| 2466/2500 [20:55<00:17,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▊| 2467/2500 [20:55<00:16,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▊| 2468/2500 [20:56<00:16,  1.96it/s]loss=0.17328675091266632\n",
      "Epoch 0:  99%|█████████▉| 2469/2500 [20:56<00:15,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  99%|█████████▉| 2470/2500 [20:57<00:15,  1.96it/s]loss=0.17328676581382751\n",
      "Epoch 0:  99%|█████████▉| 2471/2500 [20:57<00:14,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2472/2500 [20:58<00:14,  1.96it/s]loss=0.1732868105173111\n",
      "Epoch 0:  99%|█████████▉| 2473/2500 [20:58<00:13,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  99%|█████████▉| 2474/2500 [20:59<00:13,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2475/2500 [20:59<00:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2476/2500 [21:00<00:12,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2477/2500 [21:00<00:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2478/2500 [21:01<00:11,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2479/2500 [21:01<00:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2480/2500 [21:02<00:10,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2481/2500 [21:02<00:09,  1.96it/s]loss=0.1732868254184723\n",
      "Epoch 0:  99%|█████████▉| 2482/2500 [21:03<00:09,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2483/2500 [21:03<00:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2484/2500 [21:04<00:08,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2485/2500 [21:04<00:07,  1.96it/s]loss=0.17328673601150513\n",
      "Epoch 0:  99%|█████████▉| 2486/2500 [21:05<00:07,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0:  99%|█████████▉| 2487/2500 [21:05<00:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2488/2500 [21:06<00:06,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2489/2500 [21:06<00:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2490/2500 [21:07<00:05,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2491/2500 [21:07<00:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2492/2500 [21:08<00:04,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2493/2500 [21:08<00:03,  1.96it/s]loss=0.17328669130802155\n",
      "Epoch 0: 100%|█████████▉| 2494/2500 [21:09<00:03,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2495/2500 [21:09<00:02,  1.96it/s]loss=0.1732863187789917\n",
      "Epoch 0: 100%|█████████▉| 2496/2500 [21:10<00:02,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2497/2500 [21:10<00:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2498/2500 [21:11<00:01,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|█████████▉| 2499/2500 [21:11<00:00,  1.96it/s]loss=0.1732867956161499\n",
      "Epoch 0: 100%|██████████| 2500/2500 [21:12<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2500/2500 [21:14<00:00,  1.96it/s]\n",
      "GPU memory used: 20.54 GB\n"
     ]
    }
   ],
   "source": [
    "lit_model = LitRewardModel(reward_model, pairwise_loss, lr=1e-3)\n",
    "trainer = pl.Trainer(max_epochs=N_EPOCHS, logger=False)\n",
    "trainer.fit(model=lit_model, train_dataloaders=dataloader)\n",
    "# get the maximum GPU memory occupied by tensors\n",
    "mem_used = torch.cuda.max_memory_allocated()\n",
    "print(f\"GPU memory used: {mem_used / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "effdc933-4503-4846-9397-0701b72090e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLHFConfig:\n",
    "    # PPO config\n",
    "    epsilon: float = 0.1\n",
    "    # entropy coefficient\n",
    "    ent_coef: float = 0.01\n",
    "    vf_coef: float = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "805b6358-8ec6-4ced-a457-200dbba6e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RLHFTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: PreTrainedModel, # A pre-trained language model: actor\n",
    "        ref_model: PreTrainedModel, # A a reference model: critic\n",
    "        config: RLHFConfig,\n",
    "    ):\n",
    "        self.model = model.to(\"cuda\")\n",
    "        self.ref_model = ref_model.to(\"cuda\")\n",
    "        self.epsilon = config.epsilon\n",
    "        self.ent_coef = config.ent_coef\n",
    "        self.vf_coef = config.vf_coef\n",
    "    \n",
    "    @classmethod\n",
    "    def compute_advantage_and_return(\n",
    "        self,\n",
    "        rewards: TensorType[\"batch_size\"], # A list of reward values\n",
    "        values: TensorType[\"batch_size\"] # A list of predicted values from agent's value network\n",
    "    ) -> Tuple[TensorType[\"batch_size\"], TensorType[\"batch_size\"]]: # The advantages and returns\n",
    "        \"\"\"Calculate the advantages and returns.\"\"\"\n",
    "        # copied from https://github.com/lvwerra/trl/blob/d2e8bcf8373726fb92d2110c500f7df6d0bd566d/trl/trainer/ppo_trainer.py#L686\n",
    "        rewards = rearrange(rewards, 'b -> 1 b')\n",
    "        values = rearrange(values, 'b -> 1 b')\n",
    "        \n",
    "        lastgaelam = 0\n",
    "        advantages_reversed = []\n",
    "        gen_len = len(rewards)\n",
    "        \n",
    "        '''\n",
    "        discount factor: determines the relative importance of future rewards compared to immediate rewards.\n",
    "        '''\n",
    "        gamma = 1\n",
    "        '''\n",
    "        GAE parameter:  A higher value of lambda places more weight on the previous advantage estimate, \n",
    "        leading to lower variance but potentially higher bias, while a lower value of lambda places more weight\n",
    "        on the current temporal difference error, leading to higher variance but potentially lower bias.\n",
    "        '''\n",
    "        lam = 0.95\n",
    "\n",
    "        '''\n",
    "        reversed function is used to loop backwards through the time steps of the rewards and values lists.\n",
    "        '''\n",
    "        for t in reversed(range(gen_len)):\n",
    "            nextvalues = values[:, t + 1] if t < gen_len - 1 else 0.0\n",
    "            # delta: temporal difference error: difference of predicted and actual value\n",
    "            delta = rewards[:, t] + gamma * nextvalues - values[:, t]\n",
    "            lastgaelam = delta + gamma * lam * lastgaelam\n",
    "            advantages_reversed.append(lastgaelam)\n",
    "\n",
    "        # the advantage estimate for the i-th sample in the batch at time step j\n",
    "        advantages = torch.stack(advantages_reversed[::-1]).transpose(0, 1)\n",
    "        # returns is the expected return\n",
    "        returns = advantages + values\n",
    "\n",
    "        advantages = rearrange(advantages, '1 b -> b')\n",
    "        returns = rearrange(returns, '1 b -> b')\n",
    "        \n",
    "        return advantages, returns\n",
    "\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        query_ids: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        query_attention_mask: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        response_ids: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        response_attention_mask: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        rewards: TensorType[\"batch_size\"],\n",
    "    ) -> TensorType[\"1\"]:\n",
    "\n",
    "        query_ids = query_ids.to(\"cuda\")\n",
    "        query_attention_mask = query_attention_mask.to(\"cuda\")\n",
    "        response_ids = response_ids.to(\"cuda\")\n",
    "        response_attention_mask = response_attention_mask.to(\"cuda\")\n",
    "        rewards = rewards.to(\"cuda\")\n",
    "\n",
    "        \"\"\"Calculate PPO's loss.\"\"\"\n",
    "        logprobs, values, entropies, ref_logprobs = self.forward(\n",
    "            query_ids=query_ids,\n",
    "            query_attention_mask=query_attention_mask,\n",
    "            response_ids=response_ids,\n",
    "            response_attention_mask=response_attention_mask\n",
    "        )\n",
    "\n",
    "        # r_t. logprobs is new policy and ref_logprobs is old policy \n",
    "        ratio = (logprobs - ref_logprobs).exp()\n",
    "        clipped_ratio = torch.clamp(ratio, min=1-self.epsilon, max=1+self.epsilon)\n",
    "\n",
    "        # returns: expected return\n",
    "        advantages, returns = self.compute_advantage_and_return(rewards, values)\n",
    "        '''\n",
    "        measure of the accuracy of the value function in predicting the expected future reward \n",
    "        for each state\n",
    "        '''\n",
    "        value_loss = (values - returns).pow(2).mean()\n",
    "        \n",
    "        pg_loss_1 = ratio * advantages\n",
    "        pg_loss_2 = ratio * clipped_ratio\n",
    "        pg_loss = torch.min(pg_loss_1, pg_loss_2).mean()\n",
    "        \n",
    "        loss = pg_loss - self.ent_coef * entropies.mean() + self.vf_coef * value_loss\n",
    "        return loss\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        query_ids: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        query_attention_mask: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        response_ids: TensorType[\"batch_size\", \"seq_len\"],\n",
    "        response_attention_mask: TensorType[\"batch_size\", \"seq_len\"]\n",
    "    ) -> Tuple[\n",
    "        TensorType[\"batch_size\"], # main model's logprobs\n",
    "        TensorType[\"batch_size\"], # entropy\n",
    "        TensorType[\"batch_size\"], # value\n",
    "        TensorType[\"batch_size\"], # reference model's log prob\n",
    "    ]:\n",
    "        input_ids = torch.cat([query_ids, response_ids], dim=1)\n",
    "        attention_mask = torch.cat([query_attention_mask, response_attention_mask], dim=1)\n",
    "        \n",
    "        _, logprobs, entropy, value = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        _, ref_logprob, _, _ = self.ref_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask   \n",
    "        )\n",
    "            \n",
    "        return logprobs, entropy, value, ref_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2897be49-12ef-43be-9179-167159366774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would put this at the top of my list of film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Whoever wrote the screenplay for this movie ob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I can't believe that those praising this movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19325</th>\n",
       "      <td>From start to finish, I laughed real hard thro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19326</th>\n",
       "      <td>This film may seem dated today, but remember t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19327</th>\n",
       "      <td>I saw this in Detroit in what must have been i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19328</th>\n",
       "      <td>I was born in 1982. Most of my childhood memor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19329</th>\n",
       "      <td>**************Possible spoilers********** Ther...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "2      If only to avoid making this type of film in t...      0\n",
       "3      This film was probably inspired by Godard's Ma...      0\n",
       "5      I would put this at the top of my list of film...      0\n",
       "6      Whoever wrote the screenplay for this movie ob...      0\n",
       "11     I can't believe that those praising this movie...      0\n",
       "...                                                  ...    ...\n",
       "19325  From start to finish, I laughed real hard thro...      1\n",
       "19326  This film may seem dated today, but remember t...      1\n",
       "19327  I saw this in Detroit in what must have been i...      1\n",
       "19328  I was born in 1982. Most of my childhood memor...      1\n",
       "19329  **************Possible spoilers********** Ther...      1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load dataset\n",
    "\n",
    "imdb_df = pd.read_csv(\"hy-tmp/imdb.csv\")\n",
    "imdb_df = imdb_df[imdb_df['text'].str.len() <= 1000].iloc[:10000] # 10000/25000\n",
    "imdb_df\n",
    "#dataset, _ = random_split(dataset, lengths=[100, len(dataset) - 100]) # for demenstration purposes\n",
    "# train_dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4251753-ab5e-4c8f-9d70-77b17ad3be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:00, 19449.46it/s]\n"
     ]
    }
   ],
   "source": [
    "imdb_dataset = IMDBDataset(imdb_df, tokenizer)\n",
    "train_dataloader = DataLoader(imdb_dataset, batch_size=4, num_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "770a54ae-6c65-42a3-af40-ec8626dd0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the pre-trained model and tokenizer\n",
    "model_base = AutoModelForCausalLM.from_pretrained(\"hy-tmp/gpt2_CLM_local\") # for demonstration purposes\n",
    "#reward_model = RewardModel(\"gpt2\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hy-tmp/gpt2_tokenizer_local\", padding_side=\"left\")\n",
    "\n",
    "eos_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dab63eab-644c-4497-8f2b-a529dc6800cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create the RL-based language model agent and the reference model\n",
    "from copy import deepcopy\n",
    "from einops import rearrange\n",
    "\n",
    "def create_reference_model(model):\n",
    "    ref_model = deepcopy(model).eval()\n",
    "    return ref_model\n",
    "\n",
    "model = Agent(model_base)\n",
    "ref_model = create_reference_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8adb630-870c-4564-9399-f8c572af3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max length of responds\n",
    "max_new_tokens = 100\n",
    "'''\n",
    "pad_token_id: The ID of the padding token in the tokenizer's vocabulary.\n",
    "This token is used to pad the generated responses to a fixed length.\n",
    "do_sample: If True, then sampling is used to generate responses the \n",
    "model randomly selects the next word based on its predicted probabilities\n",
    "max_new_tokens:  The maximum number of new tokens to generate for each response.\n",
    "'''\n",
    "generation_kwargs = {\n",
    "    \"min_length\":-1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": max_new_tokens\n",
    "}\n",
    "\n",
    "# generate some text\n",
    "input_str = \"What is your name?\"\n",
    "input_ids = tokenizer(input_str, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "output_ids = model_base.generate(\n",
    "            input_ids = input_ids[\"input_ids\"],\n",
    "            attention_mask=input_ids[\"attention_mask\"],\n",
    "            **generation_kwargs)\n",
    "\n",
    "# decode the output\n",
    "output_str = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a9c45b9-2931-4a21-9f3b-2e3e86b2c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max length of responds\n",
    "max_new_tokens = 100\n",
    "'''\n",
    "pad_token_id: The ID of the padding token in the tokenizer's vocabulary.\n",
    "This token is used to pad the generated responses to a fixed length.\n",
    "do_sample: If True, then sampling is used to generate responses the \n",
    "model randomly selects the next word based on its predicted probabilities\n",
    "max_new_tokens:  The maximum number of new tokens to generate for each response.\n",
    "'''\n",
    "generation_kwargs = {\n",
    "    \"min_length\":-1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": max_new_tokens\n",
    "}\n",
    "\n",
    "config = RLHFConfig()\n",
    "N_EPOCH = 2\n",
    "trainer = RLHFTrainer(model, ref_model, config)\n",
    "# the optimizer will only update the model's para instead of ref_model para \n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e9c60e0-82f6-44b3-a3e6-fd5df84f27fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 100/2500, total_loss=-8.292320251464844, len 100 ,loss=-0.08292320370674133\n",
      "epoch 0, batch 200/2500, total_loss=-0.8824985027313232, len 99 ,loss=-0.008914126083254814\n",
      "epoch 0, batch 300/2500, total_loss=-0.8859870433807373, len 99 ,loss=-0.008949363604187965\n",
      "epoch 0, batch 400/2500, total_loss=-0.9168435335159302, len 99 ,loss=-0.009261045604944229\n",
      "epoch 0, batch 500/2500, total_loss=-0.947441041469574, len 99 ,loss=-0.009570111520588398\n",
      "epoch 0, batch 600/2500, total_loss=-0.9568154811859131, len 99 ,loss=-0.009664802812039852\n",
      "epoch 0, batch 700/2500, total_loss=-0.9566261172294617, len 99 ,loss=-0.009662889875471592\n",
      "epoch 0, batch 800/2500, total_loss=-0.9607317447662354, len 99 ,loss=-0.009704360738396645\n",
      "epoch 0, batch 900/2500, total_loss=-0.967468798160553, len 99 ,loss=-0.009772412478923798\n",
      "epoch 0, batch 1000/2500, total_loss=-0.9761909246444702, len 99 ,loss=-0.009860514663159847\n",
      "epoch 0, batch 1100/2500, total_loss=-0.9813780188560486, len 99 ,loss=-0.009912909008562565\n",
      "epoch 0, batch 1200/2500, total_loss=-0.9721969962120056, len 99 ,loss=-0.009820171631872654\n",
      "epoch 0, batch 1300/2500, total_loss=-0.974284291267395, len 99 ,loss=-0.009841255843639374\n",
      "epoch 0, batch 1400/2500, total_loss=-0.9762876629829407, len 99 ,loss=-0.009861491620540619\n",
      "epoch 0, batch 1500/2500, total_loss=-0.9768226742744446, len 99 ,loss=-0.009866896085441113\n",
      "epoch 0, batch 1600/2500, total_loss=-0.971941351890564, len 99 ,loss=-0.009817589074373245\n",
      "epoch 0, batch 1700/2500, total_loss=-0.9892348051071167, len 99 ,loss=-0.009992270730435848\n",
      "epoch 0, batch 1800/2500, total_loss=-0.978585422039032, len 99 ,loss=-0.009884701110422611\n",
      "epoch 0, batch 1900/2500, total_loss=-0.9795944094657898, len 99 ,loss=-0.009894892573356628\n",
      "epoch 0, batch 2000/2500, total_loss=-0.9800443053245544, len 99 ,loss=-0.009899437427520752\n",
      "epoch 0, batch 2100/2500, total_loss=-0.982140839099884, len 99 ,loss=-0.009920614771544933\n",
      "epoch 0, batch 2200/2500, total_loss=-0.9811828136444092, len 99 ,loss=-0.009910937398672104\n",
      "epoch 0, batch 2300/2500, total_loss=-0.981288731098175, len 99 ,loss=-0.009912007488310337\n",
      "epoch 0, batch 2400/2500, total_loss=-0.9871379137039185, len 99 ,loss=-0.009971089661121368\n",
      "epoch 1, batch 100/2500, total_loss=-0.9929603934288025, len 100 ,loss=-0.009929603897035122\n",
      "epoch 1, batch 200/2500, total_loss=-0.9834665060043335, len 99 ,loss=-0.009934005327522755\n",
      "epoch 1, batch 300/2500, total_loss=-0.9847339391708374, len 99 ,loss=-0.009946807287633419\n",
      "epoch 1, batch 400/2500, total_loss=-0.976613461971283, len 99 ,loss=-0.009864781983196735\n",
      "epoch 1, batch 500/2500, total_loss=-0.9855674505233765, len 99 ,loss=-0.009955226443707943\n",
      "epoch 1, batch 600/2500, total_loss=-0.9897636771202087, len 99 ,loss=-0.009997612796723843\n",
      "epoch 1, batch 700/2500, total_loss=-0.9843452572822571, len 99 ,loss=-0.009942881762981415\n",
      "epoch 1, batch 800/2500, total_loss=-0.9854407906532288, len 99 ,loss=-0.009953947737812996\n",
      "epoch 1, batch 900/2500, total_loss=-0.9875276684761047, len 99 ,loss=-0.009975027292966843\n",
      "epoch 1, batch 1000/2500, total_loss=-0.9859980344772339, len 99 ,loss=-0.009959575720131397\n",
      "epoch 1, batch 1100/2500, total_loss=-0.9920215606689453, len 99 ,loss=-0.010020419955253601\n",
      "epoch 1, batch 1200/2500, total_loss=-0.9853234887123108, len 99 ,loss=-0.00995276216417551\n",
      "epoch 1, batch 1300/2500, total_loss=-0.9850977659225464, len 99 ,loss=-0.009950482286512852\n",
      "epoch 1, batch 1400/2500, total_loss=-1.2087651491165161, len 99 ,loss=-0.012209748849272728\n",
      "epoch 1, batch 1500/2500, total_loss=-0.9855715036392212, len 99 ,loss=-0.009955267421901226\n",
      "epoch 1, batch 1600/2500, total_loss=-0.9877460598945618, len 99 ,loss=-0.009977232664823532\n",
      "epoch 1, batch 1700/2500, total_loss=-0.9860158562660217, len 99 ,loss=-0.009959756396710873\n",
      "epoch 1, batch 1800/2500, total_loss=-1.0068527460098267, len 99 ,loss=-0.010170229710638523\n",
      "epoch 1, batch 1900/2500, total_loss=-0.9861698746681213, len 99 ,loss=-0.00996131170541048\n",
      "epoch 1, batch 2000/2500, total_loss=-1.0059657096862793, len 99 ,loss=-0.010161269456148148\n",
      "epoch 1, batch 2100/2500, total_loss=-0.9871358275413513, len 99 ,loss=-0.009971069172024727\n",
      "epoch 1, batch 2200/2500, total_loss=-0.9861156940460205, len 99 ,loss=-0.009960765019059181\n",
      "epoch 1, batch 2300/2500, total_loss=-1.0124027729034424, len 99 ,loss=-0.010226290673017502\n",
      "epoch 1, batch 2400/2500, total_loss=-1.461707353591919, len 99 ,loss=-0.01476472057402134\n"
     ]
    }
   ],
   "source": [
    "total_num_batch = len(train_dataloader)\n",
    "total_loss = [] \n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    total_loss = [] \n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        inputs_truncated = {\n",
    "            key: tensor[:, :512] for key, tensor in inputs.items()\n",
    "        }\n",
    "        \n",
    "        response_ids = model.generate(\n",
    "            input_ids = inputs_truncated[\"input_ids\"],\n",
    "            attention_mask=inputs_truncated[\"attention_mask\"],\n",
    "            **generation_kwargs\n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        extract the last max_new_tokens generated text including padding\n",
    "        to ensure response have the same length \n",
    "        '''\n",
    "        response_ids = response_ids[:, -max_new_tokens:]\n",
    "        response_attention_mask = torch.ones_like(response_ids)\n",
    "        \n",
    "        # evaluate from the reward model\n",
    "        # reward_model is trained separatly\n",
    "        with torch.no_grad():\n",
    "            text_input_ids = torch.stack([torch.concat([q, r]) for q, r in zip(inputs[\"input_ids\"].to(\"cuda\"), response_ids.to(\"cuda\"))], dim=0).to(\"cuda\")\n",
    "            reward_model = reward_model.to(\"cuda\")\n",
    "            rewards = reward_model(response_ids.to(\"cuda\"))\n",
    "        \n",
    "        # calculate PPO loss\n",
    "        loss = trainer.compute_loss(\n",
    "            query_ids=inputs[\"input_ids\"],\n",
    "            query_attention_mask=inputs[\"attention_mask\"],\n",
    "            response_ids=response_ids,\n",
    "            response_attention_mask=response_attention_mask,\n",
    "            rewards=rewards\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # compute gradient \n",
    "        optimizer.step() # update parameters\n",
    "\n",
    "        if i%100 == 0 and i != 0:\n",
    "            print(f\"epoch {epoch}, batch {i}/{total_num_batch}, total_loss={sum(total_loss)}, len {len(total_loss)} ,loss={sum(total_loss)/len(total_loss)}\")\n",
    "            total_loss = [] \n",
    "        else:\n",
    "            total_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f325d75-49da-4e8f-8625-9dac29b53b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the movie transformers?oisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisoisois\n"
     ]
    }
   ],
   "source": [
    "# generate some text\n",
    "input_str = \"How is the movie transformers?\"\n",
    "input_ids = tokenizer(input_str, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "output_ids = model.generate(\n",
    "            input_ids = input_ids[\"input_ids\"],\n",
    "            attention_mask=input_ids[\"attention_mask\"],\n",
    "            **generation_kwargs)\n",
    "\n",
    "# decode the output\n",
    "output_str = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1384ad-801a-46f0-86c1-7fea7715d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Step 2: Load the pre-trained model and tokenizer\n",
    "model_base = AutoModelForCausalLM.from_pretrained(\"hy-tmp/gpt2_CLM_local\") # for demonstration purposes\n",
    "#reward_model = RewardModel(\"gpt2\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hy-tmp/gpt2_tokenizer_local\", padding_side=\"left\")\n",
    "\n",
    "eos_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0578ad94-8424-4e08-b34a-201d3e666ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your name? Otherwords when seeking contributors can survive better than digital decentralisation. I lay out my slogan on the\n"
     ]
    }
   ],
   "source": [
    "# max length of responds\n",
    "max_new_tokens = 20\n",
    "'''\n",
    "pad_token_id: The ID of the padding token in the tokenizer's vocabulary.\n",
    "This token is used to pad the generated responses to a fixed length.\n",
    "do_sample: If True, then sampling is used to generate responses the \n",
    "model randomly selects the next word based on its predicted probabilities\n",
    "max_new_tokens:  The maximum number of new tokens to generate for each response.\n",
    "'''\n",
    "generation_kwargs = {\n",
    "    \"min_length\":-1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "    \"max_new_tokens\": max_new_tokens\n",
    "}\n",
    "\n",
    "# generate some text\n",
    "input_str = \"What is your name?\"\n",
    "input_ids = tokenizer(input_str, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "output_ids = model_base.generate(\n",
    "            input_ids = input_ids[\"input_ids\"],\n",
    "            attention_mask=input_ids[\"attention_mask\"],\n",
    "            **generation_kwargs)\n",
    "\n",
    "# decode the output\n",
    "output_str = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d26ee-4557-4ed0-a093-c03755378e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
